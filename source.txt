=== BEGIN FILE: interpreter_ops.go ===
// interpreter_ops.go — PRIVATE: language ops (built-ins, assignment, iteration)
// and the AST → bytecode emitter used by the exec layer.
//
// This file:
//  - Implements `newOps(ip)` with `initCore()` (registers all core natives).
//  - Provides assignment semantics (`assignTo`) and helpers.
//  - Normalizes collections to iterators (`__to_iter`) and drives iteration.
//  - Implements deep value equality for const interning in the emitter.
//  - Hosts the private emitter (`newEmitter`) used by exec for JIT.
//
// Public API is in interpreter.go. Exec/call engine is in interpreter_exec.go.
//
// Concurrency model (minimal, Lua-style isolates):
//  - A single *Interpreter is **not re-entrant**; do not call it from multiple
//    goroutines. For parallelism, clone via (*Interpreter).Clone() and use the
//    clone in another goroutine. Each clone has its own Core/Global/env graph,
//    module cache, and source-tracking, so no locks are required here.
//  - All state touched in this file is per-interpreter (o.ip / ip.*). There are
//    no package-level mutable singletons. As long as an Interpreter isn't shared
//    concurrently, operations here are race-free without additional locking.
//  - Host native functions you register may themselves use goroutines, but they
//    must not touch the *same* Interpreter or its Env from multiple goroutines.
//    Use isolates (clones) for truly concurrent execution.

package mindscript

import (
	"fmt"
	"strings"
)

////////////////////////////////////////////////////////////////////////////////
//                         PRIVATE PANIC / ERROR HELPERS
////////////////////////////////////////////////////////////////////////////////

type returnSig struct{ v Value }
type rtErr struct {
	msg  string
	src  *SourceRef
	line int
	col  int
}

func fail(msg string)          { panic(rtErr{msg: msg}) }
func errNull(msg string) Value { return withAnnot(Null, msg) }
func annotNull(msg string) Value {
	return Value{Tag: VTNull, Annot: msg}
}
func withAnnot(v Value, ann string) Value { v.Annot = ann; return v }

// panicRt rethrows a structured runtime error as a **value** (never a pointer).
// Always use this (or fail) to signal runtime errors within the interpreter.
func panicRt(msg string, src *SourceRef, line, col int) {
	panic(rtErr{msg: msg, src: src, line: line, col: col})
}

////////////////////////////////////////////////////////////////////////////////
//                          PRIVATE OPS FACADE (to API)
////////////////////////////////////////////////////////////////////////////////

type opsImpl struct{ ip *Interpreter }

func newOps(ip *Interpreter) opsCore { return &opsImpl{ip: ip} }

func (o *opsImpl) initCore() {
	ip := o.ip
	if ip.Core == nil {
		ip.Core = NewEnv(nil)
	}
	// sugar for native registration with a ctx-only closure
	reg := func(name string, params []ParamSpec, ret S, body func(ctx CallCtx) Value) {
		ip.RegisterNative(name, params, ret, func(_ *Interpreter, ctx CallCtx) Value { return body(ctx) })
	}

	// __assign_set(targetAst: Any, value: Any) -> Any
	reg("__assign_set",
		[]ParamSpec{{"targetAst", S{"id", "Any"}}, {"value", S{"id", "Any"}}},
		S{"id", "Any"},
		func(ctx CallCtx) Value {
			ast := expectAST(ctx.MustArg("targetAst"), "__assign_set")
			v := ctx.MustArg("value")
			ip.assignTo(ast, v, ctx.Env())
			return v
		})

	// __assign_def(targetAst: Any, value: Any) -> Any
	reg("__assign_def",
		[]ParamSpec{{"targetAst", S{"id", "Any"}}, {"value", S{"id", "Any"}}},
		S{"id", "Any"},
		func(ctx CallCtx) Value {
			ast := expectAST(ctx.MustArg("targetAst"), "__assign_def")
			v := ctx.MustArg("value")
			ip.assignTo(ast, v, ctx.Env(), true)
			return v
		})

	// __plus (numbers/strings/arrays/maps)
	reg("__plus",
		[]ParamSpec{{"a", S{"id", "Any"}}, {"b", S{"id", "Any"}}}, S{"id", "Any"},
		func(ctx CallCtx) Value {
			a := AsMapValue(ctx.MustArg("a"))
			b := AsMapValue(ctx.MustArg("b"))
			if isNumber(a) && isNumber(b) {
				if a.Tag == VTInt && b.Tag == VTInt {
					return Int(a.Data.(int64) + b.Data.(int64))
				}
				return Num(toFloat(a) + toFloat(b))
			}
			if a.Tag == VTStr && b.Tag == VTStr {
				return Str(a.Data.(string) + b.Data.(string))
			}
			if a.Tag == VTArray && b.Tag == VTArray {
				x := append(append([]Value{}, a.Data.(*ArrayObject).Elems...),
					b.Data.(*ArrayObject).Elems...)
				return Arr(x)
			}
			if a.Tag == VTMap && b.Tag == VTMap {
				am, bm := a.Data.(*MapObject), b.Data.(*MapObject)
				out := &MapObject{
					Entries: make(map[string]Value, len(am.Entries)+len(bm.Entries)),
					KeyAnn:  make(map[string]string, len(am.KeyAnn)+len(bm.KeyAnn)),
					Keys:    make([]string, 0, len(am.Keys)+len(bm.Keys)),
				}
				seen := make(map[string]struct{}, len(am.Keys)+len(bm.Keys))
				// LHS order/content
				for _, k := range am.Keys {
					out.Keys = append(out.Keys, k)
					seen[k] = struct{}{}
				}
				for k, v := range am.Entries {
					out.Entries[k] = v
				}
				for k, ann := range am.KeyAnn {
					out.KeyAnn[k] = ann
				}
				// overlay RHS; append new keys in RHS order
				for _, k := range bm.Keys {
					if _, ok := seen[k]; !ok {
						out.Keys = append(out.Keys, k)
						seen[k] = struct{}{}
					}
				}
				for k, v := range bm.Entries {
					out.Entries[k] = v
				}
				for k, ann := range bm.KeyAnn {
					out.KeyAnn[k] = ann
				}
				return Value{Tag: VTMap, Data: out}
			}
			return errNull("unsupported operands for '+'")
		})

	// __resolve_type: Value(Type) -> Value(Type(resolved))
	reg("__resolve_type",
		[]ParamSpec{{"t", S{"id", "Type"}}}, S{"id", "Type"},
		func(ctx CallCtx) Value {
			t := ctx.MustArg("t")
			resolved := ip.resolveTypeValue(t, ctx.Env())
			// Always return a pinned Type; never emit env-less types.
			return TypeValIn(resolved, ctx.Env())
		})

	// __type_from_ast(ast: Any-handle) -> Type
	// Build a Type at *instantiation* time from a serialized S-expression,
	// pinning it to the current lexical environment (like closures do).
	reg("__type_from_ast",
		[]ParamSpec{{"ast", S{"id", "Any"}}}, S{"id", "Type"},
		func(ctx CallCtx) Value {
			h := ctx.MustArg("ast")
			if h.Tag != VTHandle {
				return errNull("__type_from_ast: expected internal type-ast handle")
			}
			hd := h.Data.(*Handle)
			if hd == nil || hd.Kind != "type-ast" {
				return errNull("__type_from_ast: bad handle kind")
			}
			s, ok := hd.Data.(S)
			if !ok {
				return errNull("__type_from_ast: payload not a type AST")
			}
			if msg := validateTypeShape(s); msg != "" {
				fail(msg)
			}
			return TypeValIn(s, ctx.Env())
		})

	// __annotate(text: Str, v: Any) -> Any
	reg("__annotate",
		[]ParamSpec{{"text", S{"id", "Str"}}, {"v", S{"id", "Any"}}}, S{"id", "Any"},
		func(ctx CallCtx) Value { return withAnnot(ctx.MustArg("v"), ctx.MustArg("text").Data.(string)) })

	// __collect_for_elems(iter: Any) -> Any   (used by high-level mapping helpers)
	reg("__collect_for_elems",
		[]ParamSpec{{"iter", S{"id", "Any"}}}, S{"id", "Any"},
		func(ctx CallCtx) (out Value) {
			defer func() {
				if r := recover(); r != nil {
					if e, ok := r.(rtErr); ok {
						out = errNull(e.msg)
						return
					}
					panic(r)
				}
			}()
			out = Arr(ip.collectForElemsScoped(ctx.MustArg("iter"), ctx.Env()))
			return
		})

	// __map_from(keys:[Str], vals:[Any]) -> Map
	reg("__map_from",
		[]ParamSpec{{"keys", S{"array", S{"id", "Str"}}}, {"vals", S{"array", S{"id", "Any"}}}}, S{"id", "Any"},
		func(ctx CallCtx) Value {
			ka := ctx.MustArg("keys").Data.(*ArrayObject).Elems
			va := ctx.MustArg("vals").Data.(*ArrayObject).Elems
			if len(ka) != len(va) {
				return errNull("map_from: mismatched arity")
			}
			mo := &MapObject{
				Entries: make(map[string]Value, len(ka)),
				KeyAnn:  make(map[string]string, len(ka)),
				Keys:    make([]string, 0, len(ka)),
			}
			for i := range ka {
				if ka[i].Tag != VTStr {
					return errNull("map key must be string")
				}
				k := ka[i].Data.(string)
				mo.Entries[k] = va[i]
				mo.Keys = append(mo.Keys, k)
				if ann := ka[i].Annot; ann != "" {
					mo.KeyAnn[k] = ann
				}
			}
			return Value{Tag: VTMap, Data: mo}
		})

	// __len(array|map) -> Int
	reg("__len",
		[]ParamSpec{{"x", S{"id", "Any"}}}, S{"id", "Int"},
		func(ctx CallCtx) Value {
			x := AsMapValue(ctx.MustArg("x"))
			switch x.Tag {
			case VTArray:
				return Int(int64(len(x.Data.(*ArrayObject).Elems)))
			case VTMap:
				return Int(int64(len(x.Data.(*MapObject).Entries)))
			default:
				return errNull("len expects array or map")
			}
		})

	// __make_fun(params:[Str], types:[Type], ret:Type, bodyAst:Any, isOracle:Bool, examples:Any, basePath:[Int]) -> Fun
	ip.RegisterNative("__make_fun",
		[]ParamSpec{
			{"params", S{"array", S{"id", "Str"}}},
			{"types", S{"array", S{"id", "Type"}}},
			{"ret", S{"id", "Type"}},
			{"bodyAst", S{"id", "Any"}},
			{"isOracle", S{"id", "Bool"}},
			{"examples", S{"id", "Any"}},
			{"basePath", S{"array", S{"id", "Int"}}},
		},
		S{"id", "Any"},
		func(ip *Interpreter, ctx CallCtx) Value {
			namesV := ctx.MustArg("params").Data.(*ArrayObject).Elems
			typesV := ctx.MustArg("types").Data.(*ArrayObject).Elems
			retTV := ctx.MustArg("ret").Data.(*TypeValue)
			bodyAny := ctx.MustArg("bodyAst")
			isOr := ctx.MustArg("isOracle").Data.(bool)
			exAny := ctx.MustArg("examples")
			baseAny := ctx.MustArg("basePath")

			names := make([]string, len(namesV))
			types := make([]S, len(typesV))
			for i := range namesV {
				names[i] = namesV[i].Data.(string)
			}
			for i := range typesV {
				types[i] = typesV[i].Data.(*TypeValue).Ast
			}

			// ---- Validate and box examples as a VTArray of [input, output] pairs ----
			var examples Value
			if exAny.Tag == VTNull {
				examples = Arr(nil)
			} else if exAny.Tag == VTArray {
				pairs := exAny.Data.(*ArrayObject).Elems
				for i, ex := range pairs {
					if ex.Tag != VTArray {
						return errNull(fmt.Sprintf("examples[%d] must be [input, output] (array of length 2)", i))
					}
					pp := ex.Data.(*ArrayObject).Elems
					if len(pp) != 2 {
						return errNull(fmt.Sprintf("examples[%d] must be [input, output] (array of length 2)", i))
					}
				}
				// Detach the slice so later mutations to the caller's array don't alias.
				examples = Arr(append([]Value(nil), pairs...))
			} else {
				return errNull("examples must be an array of [input, output] pairs (or null)")
			}

			hidden := false
			if len(names) == 0 {
				names = []string{"_"}
				types = []S{S{"id", "Null"}}
				hidden = true
			}

			// Build absolute base path for the body
			var base NodePath
			if baseAny.Tag == VTArray {
				xs := baseAny.Data.(*ArrayObject).Elems
				base = make(NodePath, 0, len(xs))
				for _, v := range xs {
					if v.Tag == VTInt {
						base = append(base, int(v.Data.(int64)))
					}
				}
			}

			retAst := retTV.Ast
			if isOr {
				retAst = ensureNullableUnlessAny(retAst)
			}

			// Clone current SourceRef and attach base path
			var sr *SourceRef
			if ip.currentSrc != nil {
				cpy := *ip.currentSrc
				// IMPORTANT: 'base' is ABSOLUTE - overwrite.
				cpy.PathBase = append(NodePath(nil), base...)
				sr = &cpy
			}

			// Unbox function BODY from AST handle ----
			bodyAst := expectAST(bodyAny, "__make_fun")

			// Build closure env that carries hidden signature metadata
			closure := NewEnv(ctx.Env())
			nameVals := make([]Value, len(names))
			for i, n := range names {
				nameVals[i] = Str(n)
			}
			typeVals := make([]Value, len(types))
			for i, t := range types {
				typeVals[i] = TypeValIn(t, closure)
			}
			closure.Define("$__sig_names", Arr(nameVals))
			closure.Define("$__sig_types", Arr(typeVals))

			// Construct the function with this closure
			return FunVal(&Fun{
				Params:     names,
				ParamTypes: types,
				ReturnType: retAst,
				Body:       bodyAst,
				Env:        closure, // <-- use the closure with hidden signature
				HiddenNull: hidden,
				IsOracle:   isOr,
				Examples:   examples,
				Src:        sr,
			})
		})

	// __is_fun(x: Any) -> Bool
	reg("__is_fun",
		[]ParamSpec{{"x", S{"id", "Any"}}}, S{"id", "Bool"},
		func(ctx CallCtx) Value { return Bool(ctx.MustArg("x").Tag == VTFun) })

	// __iter_should_stop(x: Any) -> Bool
	reg("__iter_should_stop",
		[]ParamSpec{{"x", S{"id", "Any"}}}, S{"id", "Bool"},
		func(ctx CallCtx) Value {
			v := ctx.MustArg("x")
			if v.Tag == VTNull {
				if v.Annot != "" {
					fail(v.Annot)
				}
				return Bool(true)
			}
			return Bool(false)
		})

	// __to_iter(x: Any) -> (Null -> Any?)  |  error
	ip.RegisterNative("__to_iter",
		[]ParamSpec{{"x", S{"id", "Any"}}}, S{"id", "Any"},
		func(ip *Interpreter, ctx CallCtx) Value {
			x := AsMapValue(ctx.MustArg("x"))

			// Already an iterator?
			if x.Tag == VTFun {
				f := x.Data.(*Fun)
				if len(f.Params) == 1 && ip.isType(Null, f.ParamTypes[0], f.Env) {
					return x
				}
				fail("for expects array, map, or iterator function (Null -> Any?)")
			}

			// Helpers
			newIter := func(parent *Env, lenTarget S, thenBlock S) Value {
				env := NewEnv(parent)
				env.Define("$i", Int(0))
				body := S{"if",
					S{"pair",
						S{"binop", "<",
							S{"id", "$i"},
							S{"call", S{"id", "__len"}, lenTarget},
						},
						S{"block", thenBlock},
					},
					S{"block", S{"null"}},
				}
				var sr *SourceRef
				if ip.currentSrc != nil {
					cpy := *ip.currentSrc // shallow copy; Spans pointer intentionally shared
					sr = &cpy
				}
				return FunVal(&Fun{
					Params:     []string{"_"},
					ParamTypes: []S{S{"id", "Null"}},
					ReturnType: S{"unop", "?", S{"id", "Any"}},
					Body:       body,
					Env:        env,
					Src:        sr,
				})
			}
			inc := func() S {
				return S{"assign", S{"id", "$i"},
					S{"binop", "+", S{"id", "$i"}, S{"int", int64(1)}},
				}
			}

			// Array → iterator
			if x.Tag == VTArray {
				envInit := NewEnv(ctx.Env())
				envInit.Define("$arr", x)
				then := S{"block",
					inc(),
					S{"idx",
						S{"id", "$arr"},
						S{"binop", "-", S{"id", "$i"}, S{"int", int64(1)}},
					},
				}
				return newIter(envInit, S{"id", "$arr"}, then)
			}

			// Map → iterator (yields [key, value]) preserving insertion order + key annotations
			if x.Tag == VTMap {
				mo := x.Data.(*MapObject)
				envInit := NewEnv(ctx.Env())
				envInit.Define("$map", x)
				keyVals := make([]Value, 0, len(mo.Keys))
				for _, k := range mo.Keys {
					s := Str(k)
					if ann, ok := mo.KeyAnn[k]; ok && ann != "" {
						s = withAnnot(s, ann)
					}
					keyVals = append(keyVals, s)
				}
				envInit.Define("$keys", Arr(keyVals))

				then := S{"block",
					S{"assign", S{"decl", "$k"},
						S{"idx", S{"id", "$keys"}, S{"id", "$i"}},
					},
					inc(),
					S{"array",
						S{"id", "$k"},
						S{"idx", S{"id", "$map"}, S{"id", "$k"}},
					},
				}
				return newIter(envInit, S{"id", "$keys"}, then)
			}

			fail("for expects array, map, or iterator function (Null -> Any?)")
			return annotNull("__for_iter: unreachable")
		})

	ip.RegisterNative(
		"__make_module",
		[]ParamSpec{
			{Name: "name", Type: S{"id", "Str"}}, // keep lax; runtime checks enforce string
			{Name: "body", Type: S{"id", "Any"}}, // Type-carried AST
			{Name: "base", Type: S{"id", "Any"}}, // [Int] path
		},
		S{"id", "Any"}, // could be a dedicated Module type later; Any is simplest now
		nativeMakeModule,
	)
}

////////////////////////////////////////////////////////////////////////////////
//                                ASSIGNMENT
////////////////////////////////////////////////////////////////////////////////

func (ip *Interpreter) assignTo(target S, value Value, env *Env, optAllowDefine ...bool) {
	allowDefine := len(optAllowDefine) > 0 && optAllowDefine[0]
	switch target[0].(string) {
	case "id":
		name := target[1].(string)
		if err := env.Set(name, value); err != nil {
			if allowDefine {
				env.Define(name, value)
				return
			}
			fail(err.Error())
		}
	case "decl":
		env.Define(target[1].(string), value)
	case "get":
		obj := ip.evalFull(target[1].(S), env)
		// resolve key string (literal or computed)
		var keyStr string
		if ks := target[2].(S); len(ks) >= 2 && (ks[0].(string) == "id" || ks[0].(string) == "str") {
			keyStr = ks[1].(string)
		} else {
			k := ip.evalFull(target[2].(S), env)
			if k.Tag != VTStr {
				fail("object assignment requires map and string key")
			}
			keyStr = k.Data.(string)
		}
		mv := AsMapValue(obj)
		if mv.Tag == VTMap {
			mo := mv.Data.(*MapObject)
			if _, exists := mo.Entries[keyStr]; !exists {
				mo.Keys = append(mo.Keys, keyStr)
			}
			mo.Entries[keyStr] = value
			syncModuleEnv(obj, keyStr, value) // no-op for plain maps
			return
		}
		if obj.Tag == VTModule {
			fail("object assignment requires map and string key") // unreachable, safety
		}
		if obj.Tag == VTArray {
			fail("object assignment requires map and string key")
		}
		fail("object assignment requires map and string key")
	case "idx":
		obj, idx := ip.evalFull(target[1].(S), env), ip.evalFull(target[2].(S), env)
		if obj.Tag == VTArray && idx.Tag == VTInt {
			xs := obj.Data.(*ArrayObject).Elems
			if len(xs) == 0 {
				fail("index on empty array")
			}
			i := int(idx.Data.(int64))
			if i < 0 {
				i = len(xs) + i // -1 -> last, -len -> 0
			}
			if i < 0 || i >= len(xs) {
				fail("array index out of range")
			}
			xs[i] = value
			return
		}
		mv := AsMapValue(obj)
		if mv.Tag == VTMap && idx.Tag == VTStr {
			mo := mv.Data.(*MapObject)
			k := idx.Data.(string)
			if _, exists := mo.Entries[k]; !exists {
				mo.Keys = append(mo.Keys, k)
			}
			mo.Entries[k] = value
			syncModuleEnv(obj, k, value)
			return
		}
		fail("index assignment requires array[int] or map[string]")
	case "darr":
		if value.Tag != VTArray {
			for i := 1; i < len(target); i++ {
				ip.assignTo(target[i].(S), annotNull("array pattern: RHS is not an array"), env, true)
			}
			return
		}
		xs := value.Data.(*ArrayObject).Elems
		for i := 1; i < len(target); i++ {
			if i-1 < len(xs) {
				ip.assignTo(target[i].(S), xs[i-1], env, true)
			} else {
				ip.assignTo(target[i].(S), annotNull(fmt.Sprintf("array pattern: missing element #%d", i-1)), env, true)
			}
		}
	case "dobj":
		vmap := AsMapValue(value)
		if vmap.Tag != VTMap {
			for i := 1; i < len(target); i++ {
				p := target[i].(S) // ("pair", key, pattern)
				ip.assignTo(p[2].(S), annotNull("object pattern: RHS is not a map"), env, true)
			}
			return
		}
		mo := vmap.Data.(*MapObject)
		m := mo.Entries
		for i := 1; i < len(target); i++ {
			p := target[i].(S)
			k := unwrapKeyStr(p[1].(S))
			if v, ok := m[k]; ok {
				ip.assignTo(p[2].(S), v, env, true)
			} else {
				ip.assignTo(p[2].(S), annotNull(fmt.Sprintf("object pattern: missing key '%s'", k)), env, true)
			}
		}
	case "annot":
		text := target[1].(S)[1].(string)
		sub := target[2].(S)
		if len(sub) > 0 && sub[0].(string) == "decl" {
			env.Define(sub[1].(string), withAnnot(value, text))
			return
		}
		ip.assignTo(sub, value, env, true)
	default:
		fail("invalid assignment target")
	}
}

// syncModuleEnv keeps a module's Env consistent after a write to its map.
// NOTE (isolates): modules live within a single Interpreter instance; this
// function updates the module's *local* Env only. Do not cross-post between
// interpreters.
func syncModuleEnv(obj Value, key string, val Value) {
	if obj.Tag == VTModule {
		m := obj.Data.(*Module)
		if _, ok := m.Env.table[key]; ok {
			m.Env.table[key] = val
		} else {
			m.Env.Define(key, val)
		}
	}
}

////////////////////////////////////////////////////////////////////////////////
//                     TINY EVALUATORS (used by assignment)
////////////////////////////////////////////////////////////////////////////////

// evalFull compiles and runs a single expression in env.
// Annotated null is turned into a runtime failure (panic(rtErr)) to align with assignment.
func (ip *Interpreter) evalFull(n S, env *Env) Value {
	em := newEmitter(ip, ip.currentSrc)
	em.emitExpr(n)
	em.emit(opReturn, 0)
	ch := em.chunk()
	res := ip.runChunk(ch, env, 0)
	switch res.status {
	case vmOK, vmReturn:
		if res.value.Tag == VTNull && res.value.Annot != "" {
			fail(res.value.Annot)
		}
		return res.value
	case vmRuntimeError:
		if res.value.Tag == VTNull && res.value.Annot != "" {
			fail(res.value.Annot)
		}
		fail("runtime error")
	default:
		fail("unknown VM status")
	}
	return Null
}

////////////////////////////////////////////////////////////////////////////////
//                             ITERATOR EXPANSION
////////////////////////////////////////////////////////////////////////////////

func (ip *Interpreter) collectForElemsScoped(iter Value, scope *Env) []Value {
	iter = AsMapValue(iter)

	// Normalize to iterator function via Core's __to_iter when needed.
	if iter.Tag != VTFun {
		toIter, err := ip.Core.Get("__to_iter")
		if err != nil {
			fail("for expects array, map, or iterator function (Null -> Any?)")
		}
		iter = ip.applyArgsScoped(toIter, []Value{iter}, scope)

		// Safety: __to_iter now fails itself for bad inputs; if it ever
		// returns non-fun here, keep the user-facing invariant.
		if iter.Tag != VTFun {
			fail("for expects array, map, or iterator function (Null -> Any?)")
		}
	}

	// At this point, iter must be a function of shape (Null) -> Any?
	f, ok := iter.Data.(*Fun)
	if !ok {
		fail("for expects array, map, or iterator function (Null -> Any?)")
	}
	if len(f.Params) != 1 || !ip.isType(Null, f.ParamTypes[0], f.Env) {
		name := "_"
		if len(f.Params) > 0 {
			name = f.Params[0]
		}
		fail(fmt.Sprintf("type mismatch in parameter '%s'", name))
	}

	stopFn, err := ip.Core.Get("__iter_should_stop")
	if err != nil {
		fail("missing __iter_should_stop")
	}

	out := []Value{}
	for {
		next := ip.applyArgsScoped(iter, []Value{Null}, scope)
		if ip.applyArgsScoped(stopFn, []Value{next}, scope).Data.(bool) {
			break
		}
		out = append(out, next)
	}
	return out
}

////////////////////////////////////////////////////////////////////////////////
//                          VALUE EQUALITY (for emitter)
////////////////////////////////////////////////////////////////////////////////

func (ip *Interpreter) deepEqual(a, b Value) bool {
	// Visited set of (leftPtr,rightPtr) pairs to break cycles in arrays/maps.
	type pair struct{ x, y any }
	visited := make(map[pair]bool)

	var eq func(x, y Value) bool
	eq = func(x, y Value) bool {
		// Treat modules as maps (same as the original function).
		if x.Tag == VTModule {
			x = Value{Tag: VTMap, Data: x.Data.(*Module).Map}
		}
		if y.Tag == VTModule {
			y = Value{Tag: VTMap, Data: y.Data.(*Module).Map}
		}

		// Numeric unification (Int/Num compare by value).
		if isNumber(x) && isNumber(y) {
			return toFloat(x) == toFloat(y)
		}

		// Tags must match (after numeric normalization above).
		if x.Tag != y.Tag {
			return false
		}

		switch x.Tag {
		case VTNull:
			return true
		case VTBool:
			return x.Data.(bool) == y.Data.(bool)
		case VTInt:
			return x.Data.(int64) == y.Data.(int64)
		case VTNum:
			return x.Data.(float64) == y.Data.(float64)
		case VTStr:
			return x.Data.(string) == y.Data.(string)

		case VTArray:
			ax := x.Data.(*ArrayObject)
			ay := y.Data.(*ArrayObject)
			// Cycle guard: if we've already compared this pair, consider it equal.
			k := pair{ax, ay}
			if visited[k] {
				return true
			}
			visited[k] = true

			if len(ax.Elems) != len(ay.Elems) {
				return false
			}
			for i := range ax.Elems {
				if !eq(ax.Elems[i], ay.Elems[i]) {
					return false
				}
			}
			return true

		case VTMap:
			mx := x.Data.(*MapObject)
			my := y.Data.(*MapObject)
			// Cycle guard for maps.
			k := pair{mx, my}
			if visited[k] {
				return true
			}
			visited[k] = true

			if len(mx.Entries) != len(my.Entries) {
				return false
			}
			for k, xv := range mx.Entries {
				yv, ok := my.Entries[k]
				if !ok || !eq(xv, yv) {
					return false
				}
			}
			return true

		case VTFun:
			// Pointer equality on closures (matches original behavior).
			return x.Data.(*Fun) == y.Data.(*Fun)

		case VTType:
			// Resolve and structurally compare type ASTs (matches original behavior).
			ta := x.Data.(*TypeValue)
			tb := y.Data.(*TypeValue)
			ea := ta.Env
			if ea == nil {
				ea = ip.Core
			}
			eb := tb.Env
			if eb == nil {
				eb = ip.Core
			}
			ra := ip.resolveType(ta.Ast, ea)
			rb := ip.resolveType(tb.Ast, eb)
			return equalLiteralS(ra, rb)

		default:
			// Handles VTHandle and any other tags we don't explicitly equal-compare.
			return false
		}
	}

	return eq(a, b)
}

////////////////////////////////////////////////////////////////////////////////
//                                SMALL HELPERS
////////////////////////////////////////////////////////////////////////////////

func isNumber(v Value) bool { return v.Tag == VTInt || v.Tag == VTNum }
func toFloat(v Value) float64 {
	if v.Tag == VTInt {
		return float64(v.Data.(int64))
	}
	return v.Data.(float64)
}

func unwrapKeyStr(k S) string {
	for len(k) > 0 && k[0].(string) == "annot" {
		k = k[2].(S)
	}
	if len(k) >= 2 && k[0].(string) == "str" {
		return k[1].(string)
	}
	fail("map key is not a string")
	return ""
}

// Noop detection: ("noop") and ("annot", ..., ("noop"), ...) are “noopish” and
// generate no code inside blocks.
func isNoopish(n S) bool {
	if len(n) == 0 {
		return false
	}
	switch n[0].(string) {
	case "noop":
		// Defensive: treat a stray ("noop") in expression position as plain Null.
		return true
	case "annot":
		// n[2] is the subject node; treat annot(noop) as noop
		if len(n) >= 3 {
			if sub, ok := n[2].(S); ok {
				return isNoopish(sub)
			}
		}
		return false
	default:
		return false
	}
}

// Given a VTType, resolve its AST using its own env if present; otherwise use fallback.
func (ip *Interpreter) resolveTypeValue(v Value, fallback *Env) S {
	if v.Tag != VTType {
		return S{"id", "Any"}
	}
	tv := v.Data.(*TypeValue)
	env := tv.Env
	if env == nil {
		env = fallback
	}
	return ip.resolveType(tv.Ast, env)
}

// "A -> B -> C -> A" using pretty names instead of full canonical specs.
func joinCyclePath(stack []string, again string) string {
	i := 0
	for idx, s := range stack {
		if s == again {
			i = idx
			break
		}
	}
	chain := append(stack[i:], again)
	out := make([]string, len(chain))
	for k, s := range chain {
		out[k] = prettySpec(s)
	}
	return strings.Join(out, " -> ")
}

// expectAST extracts an S-expression from a VTHandle("ast", ...).
// Fails with a friendly runtime error instead of panicking on bad inputs.
func expectAST(v Value, where string) S {
	if v.Tag != VTHandle {
		fail(where + ": body must be an AST handle")
	}
	hd, _ := v.Data.(*Handle)
	if hd == nil || hd.Kind != "ast" {
		fail(where + ": body must be an AST handle")
	}
	s, ok := hd.Data.(S)
	if !ok {
		fail(where + ": AST payload corrupt")
	}
	return s
}

// nativeMakeModule is the implementation of the __make_module primitive.
//
// UNIFORM CACHING & CYCLE DETECTION LIVE HERE.
// This ensures AST/Code/File/inline constructions all behave the same.
//
// It receives:
//   - name: Str   — the **canonical identity** for the module (NOT overwritten).
//   - body: Type  — AST for the module body wrapped as a type value.
//   - base: [Int] — absolute NodePath indicating where the body lives in the
//     caller’s SourceRef; used to re-root spans to the body.
//
// Plumbing:
//   - We build a child SourceRef with PathBase=base so VM marks and PC→(line,col)
//     map into the module body text.
//   - Runtime errors are rethrown with exact location using panicRt, so they
//     bubble to runTopWithSource and render a single caret at the true site.
//
// Concurrency note: module load state (ip.modules, ip.loadStack) belongs to a
// single Interpreter isolate. Do not share the same Interpreter across goroutines.
func nativeMakeModule(ip *Interpreter, ctx CallCtx) Value {
	nameV := ctx.MustArg("name")
	bodyV := ctx.MustArg("body")
	baseV := ctx.MustArg("base")

	if nameV.Tag != VTStr {
		fail("module name must be a string")
	}
	canon := nameV.Data.(string)

	// ---- Uniform cycle detection (stack + in-progress record) ----
	for _, s := range ip.loadStack {
		if s == canon {
			fail(fmt.Sprintf("import cycle detected: %s", joinCyclePath(ip.loadStack, canon)))
		}
	}
	if ip.modules != nil {
		if rec, ok := ip.modules[canon]; ok && rec.state == modLoading {
			fail(fmt.Sprintf("import cycle detected: %s", joinCyclePath(append(ip.loadStack, canon), canon)))
		}
	}

	// ---- Uniform caching (success-only) ----
	if ip.modules != nil {
		if rec, ok := ip.modules[canon]; ok && rec.state == modLoaded && rec.mod != nil {
			return Value{Tag: VTModule, Data: rec.mod}
		}
	} else {
		ip.modules = map[string]*moduleRec{}
	}

	// Mark as loading and push on stack.
	ip.modules[canon] = &moduleRec{spec: canon, state: modLoading}
	ip.loadStack = append(ip.loadStack, canon)

	// Ensure we never leave a stale modLoading record or a stuck stack entry.
	// On panic/failure, delete the cache record; always pop loadStack.
	defer func() {
		// Pop load stack
		if n := len(ip.loadStack); n > 0 {
			ip.loadStack = ip.loadStack[:n-1]
		}
		// If not successfully flipped to modLoaded, remove the half-built record.
		if rec, ok := ip.modules[canon]; ok && rec.state != modLoaded {
			delete(ip.modules, canon)
		}
		// Preserve existing error semantics.
		if r := recover(); r != nil {
			panic(r)
		}
	}()

	// ---- Decode body AST and base path ----
	bodyAst := expectAST(bodyV, "__make_module")

	// Decode absolute base path from [Int]
	var base NodePath
	if baseV.Tag == VTArray {
		xs := baseV.Data.(*ArrayObject).Elems
		base = make(NodePath, 0, len(xs))
		for _, v := range xs {
			if v.Tag != VTInt {
				fail("internal error: module base path must be [Int]")
			}
			base = append(base, int(v.Data.(int64)))
		}
	}

	// Fresh env for the module (Core is parent so builtins are visible).
	modEnv := NewEnv(ip.Core)
	modEnv.SealParentWrites()

	// SourceRef rooted at the module BODY path (absolute)
	var sr *SourceRef
	if ip.currentSrc != nil {
		// Compose any existing PathBase with the module's absolute body path.
		sr = &SourceRef{
			Name:     ip.currentSrc.Name,
			Src:      ip.currentSrc.Src,
			Spans:    ip.currentSrc.Spans, // keep full index; marks are absolute
			PathBase: append(NodePath(nil), base...),
		}
	}

	// JIT + run (like runTopWithSource, but we handle errors to avoid re-wrap)
	ch := ip.jitTop(bodyAst, sr)

	prev := ip.currentSrc
	ip.currentSrc = ch.Src
	res := ip.runChunk(ch, modEnv, 0)
	ip.currentSrc = prev

	switch res.status {
	case vmOK, vmReturn:
		// ok
	case vmRuntimeError:
		line, col := ip.sourcePosFromChunk(ch, ch.Src, res.pc)
		msg := res.value.Annot
		if msg == "" {
			msg = "runtime error"
		}
		// Rethrow as structured inner-source error (single caret at true site).
		panicRt(msg, ch.Src, line, col)
	default:
		line, col := ip.sourcePosFromChunk(ch, ch.Src, res.pc)
		panicRt("unknown VM status", ch.Src, line, col)
	}

	// Snapshot exports
	mo := buildModuleMap(modEnv)
	m := &Module{Name: canon, Map: mo, Env: modEnv}

	// Commit cache (success-only)
	rec := ip.modules[canon]
	rec.mod = m
	rec.env = modEnv
	rec.state = modLoaded
	rec.err = nil

	return Value{Tag: VTModule, Data: m}
}
=== END FILE: interpreter_ops.go ===

=== BEGIN FILE: interpreter_exec.go ===
// interpreter_exec.go — PRIVATE: execution & call engine for MindScript.
//   - Parses source (via lexer/parser), compiles S-expr → bytecode (via emitter),
//     runs on the VM, and **bubbles unified hard errors (*Error) without formatting**.
//   - Implements function application, currying, and native-call scoping.
//   - No exported identifiers here. The public facade lives in interpreter.go.
//
// ──────────────────────────────────────────────────────────────────────────────
// MARKING PLAN (PRECISE CARETS)
// =============================
//
// We make runtime caret locations precise and predictable by aligning VM marks
// with parser spans.
//
// Invariants
// ----------
//  1. **1:1 Node ↔ Span (parser)** — the parser records exactly one Span per AST
//     node (every subexpression has a node and a span).
//  2. **1:1 Node ↔ Mark (emitter)** — the emitter records **exactly one** PCMark
//     for every AST node it emits code for. (Nodes that truly produce no code do
//     not get a mark unless they are direct failure targets.)
//  3. **Monotonic marks** — marks are appended in bytecode order with PC=here().
//  4. **No late parent marks** — once we place a child’s mark immediately before
//     a failure-prone instruction, we must not emit a parent/sibling mark before
//     that instruction executes.
//  5. **Correct PathBase** — chunks compiled for function bodies / module bodies
//     carry a SourceRef whose PathBase points at the body’s absolute AST path,
//     so marks inside map to the right spans.
//
// Placement Rules (authoritative)
// -------------------------------
//   - **Identifiers**: mark the identifier node **right before** opLoadGlobal.
//   - **Unary** (-, not): mark the operand **right before** the opcode.
//   - **Binary** (-,*,/,%, <,<=,>,>=, ==, !=): emit LHS, then RHS; mark the **RHS**
//     **right before** the arithmetic/compare opcode (or before the builtin CALL
//     for '+', which lowers to __plus).
//   - **Calls**: evaluate callee (no mark). For each argument:
//     1) emit arg code
//     2) mark the **arg node** **right before** `opCall 1`
//     3) emit `opCall 1`
//     For zero-arg call: mark the **callee** right before `opCall 0`.
//   - **Property** (`obj.name`): emit obj, mark the **property token** right before
//     `opGetProp`.
//   - **Index** (`obj[idx]`): emit obj then idx; mark the **idx node** right before
//     `opGetIdx`.
//   - **if / while gates**: mark the **tested condition node** right before
//     `opJumpIfFalse`.
//   - **Blocks**: never emit a parent mark between a child’s mark and its failing
//     instruction. No extra block-level mark is needed. **Important:** child
//     paths must use the **original AST child index** (do not compact after
//     skipping noopish children), to keep NodePath ↔ Span alignment.
//   - **Annotations**: attribute errors to the **subject** node (not the wrapper).
//     For `#(doc) (lhs = rhs)`, we mark the **LHS** before the assignment call.
//   - **for**: the iterator expression is marked once at the `__to_iter(iterExpr)`
//     call site. We do not duplicate a mark at the loop head.
//
// NOTE: These rules ensure that the VM’s “last mark with PC ≤ failingPC” picks
// the blameworthy child.
//
// Error policy (unchanged)
// ------------------------
//   - Soft errors → annotated-null Values.
//   - Hard errors → *Error {Kind, Msg, Src, Line, Col} bubbled up; formatting only
//     at the public API surface.
package mindscript

import (
	"fmt"
)

////////////////////////////////////////////////////////////////////////////////
//                          PRIVATE EXEC FACADE (to API)
////////////////////////////////////////////////////////////////////////////////

type execImpl struct{ ip *Interpreter }

func newExec(ip *Interpreter) execCore { return &execImpl{ip: ip} }

// evalSource parses + evaluates in the provided env (fresh or persistent).
// Returns Value on success; on hard failure returns a *Error with Src attached.
// No pretty printing here.
func (x *execImpl) evalSource(src string, env *Env) (Value, error) {
	ast, spans, err := ParseSExprWithSpans(src)
	if err != nil {
		if e, ok := err.(*Error); ok && e.Src == nil {
			e.Src = &SourceRef{Name: "<main>", Src: src, Spans: spans}
		}
		return Value{}, err
	}
	sr := &SourceRef{Name: "<main>", Src: src, Spans: spans}
	return x.ip.runTopWithSource(ast, env, false, sr)
}

// evalAST evaluates an AST in the provided env.
// No pretty printing here.
func (x *execImpl) evalAST(ast S, env *Env) (Value, error) {
	return x.ip.runTopWithSource(ast, env, false, nil)
}

func (x *execImpl) applyArgsScoped(fn Value, args []Value, callSite *Env) Value {
	return x.ip.applyArgsScoped(fn, args, callSite)
}

func (x *execImpl) funMeta(fn Value) (Callable, bool) {
	if fn.Tag != VTFun {
		return nil, false
	}
	return &funCallable{f: fn.Data.(*Fun), doc: fn.Annot}, true
}

////////////////////////////////////////////////////////////////////////////////
//                      CORE EXECUTION PLUMBING (PRIVATE)
////////////////////////////////////////////////////////////////////////////////

func (ip *Interpreter) runTopWithSource(ast S, env *Env, uncaught bool, sr *SourceRef) (out Value, err error) {

	// Debug spans.
	if DebuggingMode {
		_ = VerifySpanIndexPostOrder(ast, sr, 40, nil)
	}

	defer func() {
		if r := recover(); r != nil {
			switch sig := r.(type) {
			case returnSig:
				out, err = sig.v, nil
			case *Error:
				if uncaught {
					out, err = annotNull(sig.Msg), nil
					return
				}
				if sig.Src == nil {
					sig.Src = sr
				}
				err = sig
				out = Value{}
			case rtErr:
				srcRef := sig.src
				if srcRef == nil {
					srcRef = sr
				}
				line, col := sig.line, sig.col
				if line <= 0 || col <= 0 {
					line, col = ip.sourcePosFromChunk(nil, srcRef, 0)
				}
				if uncaught {
					out, err = errNull(sig.msg), nil
					return
				}
				err = &Error{Kind: DiagRuntime, Msg: sig.msg, Src: srcRef, Line: line, Col: col}
				out = Value{}
			case error:
				if uncaught {
					out, err = annotNull(sig.Error()), nil
					return
				}
				line, col := ip.sourcePosFromChunk(nil, sr, 0)
				err = &Error{Kind: DiagRuntime, Msg: sig.Error(), Src: sr, Line: line, Col: col}
				out = Value{}
			default:
				if uncaught {
					out, err = annotNull(fmt.Sprintf("runtime panic: %v", r)), nil
					return
				}
				line, col := ip.sourcePosFromChunk(nil, sr, 0)
				err = &Error{Kind: DiagRuntime, Msg: fmt.Sprintf("runtime panic: %v", r), Src: sr, Line: line, Col: col}
				out = Value{}
			}
		}
	}()

	ch := ip.jitTop(ast, sr)
	prev := ip.currentSrc
	ip.currentSrc = ch.Src
	res := ip.runChunk(ch, env, 0)
	ip.currentSrc = prev

	switch res.status {
	case vmOK, vmReturn:
		return res.value, nil
	case vmRuntimeError:
		if uncaught {
			return res.value, nil
		}
		line, col := ip.sourcePosFromChunk(ch, ch.Src, res.pc)
		msg := res.value.Annot
		if msg == "" {
			msg = "runtime error"
		}
		return Value{}, &Error{Kind: DiagRuntime, Msg: msg, Src: ch.Src, Line: line, Col: col}
	default:
		if uncaught {
			return errNull("unknown VM status"), nil
		}
		line, col := ip.sourcePosFromChunk(ch, ch.Src, res.pc)
		return Value{}, &Error{Kind: DiagRuntime, Msg: "unknown VM status", Src: ch.Src, Line: line, Col: col}
	}
}

// Build a one-off top-level function body and ensure it is compiled.
func (ip *Interpreter) jitTop(ast S, sr *SourceRef) *Chunk {
	f := &Fun{ReturnType: S{"id", "Any"}, Body: ast, Src: sr}
	ip.ensureChunkWithSource(f, sr)
	return f.Chunk
}

func (ip *Interpreter) ensureChunkWithSource(f *Fun, sr *SourceRef) {
	if f.Chunk != nil || f.NativeName != "" || f.IsOracle {
		return
	}
	em := newEmitter(ip, sr)
	em.emitFunBody(f.Body)
	ch := em.chunk()
	ch.Src = sr
	f.Chunk = ch
}

////////////////////////////////////////////////////////////////////////////////
//                    CALL ENGINE: APPLY / CURRY / EXECUTE
////////////////////////////////////////////////////////////////////////////////

func (ip *Interpreter) applyArgsScoped(fn Value, args []Value, callSite *Env) Value {
	if fn.Tag != VTFun {
		fail("not a function")
	}
	f := fn.Data.(*Fun)

	if len(args) == 0 {
		switch len(f.Params) {
		case 0:
			return ip.execFunBodyScoped(fn, callSite)
		case 1:
			if ip.isType(Null, f.ParamTypes[0], f.Env) {
				return ip.applyOneScoped(fn, Null, callSite)
			}
			fail(fmt.Sprintf("arity mismatch: expected %d, got 0", len(f.Params)))
		default:
			fail(fmt.Sprintf("arity mismatch: expected %d, got 0", len(f.Params)))
		}
	}

	cur := fn
	for i := 0; i < len(args); i++ {
		cur = ip.applyOneScoped(cur, args[i], callSite)
		if i < len(args)-1 && cur.Tag != VTFun {
			fail("too many arguments")
		}
	}
	return cur
}

func (ip *Interpreter) applyOneScoped(fnVal Value, arg Value, callSite *Env) Value {
	if fnVal.Tag != VTFun {
		fail("not a function")
	}
	f := fnVal.Data.(*Fun)

	if len(f.Params) == 0 {
		res := ip.execFunBodyScoped(fnVal, callSite)
		if res.Tag != VTFun {
			fail("too many arguments")
		}
		return ip.applyOneScoped(res, arg, callSite)
	}

	paramName := f.Params[0]
	paramType := f.ParamTypes[0]
	if !ip.isType(arg, paramType, f.Env) {
		exp := FormatType(ip.resolveType(paramType, f.Env))
		got := FormatType(ip.ValueToType(arg, f.Env))
		fail(fmt.Sprintf("type mismatch in parameter '%s': expected %s, got %s",
			paramName, exp, got))
	}

	parent := f.Env
	if f.NativeName != "" && callSite != nil {
		if f.Env == nil || f.Env == ip.Core {
			parent = callSite
		}
	}
	callEnv := NewEnv(parent)
	callEnv.Define(paramName, arg)

	if len(f.Params) > 1 {
		next := FunVal(&Fun{
			Params:     append([]string{}, f.Params[1:]...),
			ParamTypes: append([]S{}, f.ParamTypes[1:]...),
			ReturnType: f.ReturnType,
			Body:       f.Body,
			Env:        callEnv,
			HiddenNull: f.HiddenNull,
			Chunk:      f.Chunk,
			NativeName: f.NativeName,
			Src:        f.Src,
			IsOracle:   f.IsOracle,
			Examples:   f.Examples,
		})
		next.Annot = fnVal.Annot
		return next
	}

	execFun := &Fun{
		Params:     nil,
		ParamTypes: append([]S(nil), f.ParamTypes...),
		ReturnType: f.ReturnType,
		Body:       f.Body,
		Env:        callEnv,
		HiddenNull: f.HiddenNull,
		Chunk:      f.Chunk,
		NativeName: f.NativeName,
		IsOracle:   f.IsOracle,
		Examples:   f.Examples,
		Src:        f.Src,
	}
	execVal := FunVal(execFun)
	execVal.Annot = fnVal.Annot
	return ip.execFunBodyScoped(execVal, callSite)
}

func (ip *Interpreter) execFunBodyScoped(funVal Value, callSite *Env) Value {
	if funVal.Tag != VTFun {
		fail("not a function")
	}
	f := funVal.Data.(*Fun)

	if f.NativeName != "" {
		impl, ok := ip.native[f.NativeName]
		if !ok {
			fail(fmt.Sprintf("unknown native %q", f.NativeName))
		}
		scope := withScope(f.Env, callSite)
		prev := ip.currentSrc
		if f.Src != nil {
			ip.currentSrc = f.Src
		}
		res := impl(ip, &callCtx{argEnv: f.Env, scope: scope})
		ip.currentSrc = prev
		if !ip.isType(res, f.ReturnType, f.Env) {
			exp := FormatType(ip.resolveType(f.ReturnType, f.Env))
			got := FormatType(ip.ValueToType(res, f.Env))
			fail(fmt.Sprintf("return type mismatch: expected %s, got %s", exp, got))
		}
		return res
	}

	if f.IsOracle {
		scope := withScope(f.Env, callSite)
		ctx := &callCtx{argEnv: f.Env, scope: scope}
		return ip.execOracle(funVal, ctx)
	}

	ip.ensureChunkWithSource(f, f.Src)
	prev := ip.currentSrc
	if f.Src != nil {
		ip.currentSrc = f.Src
	}
	res := ip.runChunk(f.Chunk, f.Env, 0)
	ip.currentSrc = prev

	switch res.status {
	case vmOK, vmReturn:
		if !ip.isType(res.value, f.ReturnType, f.Env) {
			exp := FormatType(ip.resolveType(f.ReturnType, f.Env))
			got := FormatType(ip.ValueToType(res.value, f.Env))
			line, col := ip.sourcePosFromChunk(f.Chunk, f.Src, res.pc)
			panicRt(fmt.Sprintf("return type mismatch: expected %s, got %s", exp, got), f.Src, line, col)
		}
		return res.value
	case vmRuntimeError:
		line, col := ip.sourcePosFromChunk(f.Chunk, f.Src, res.pc)
		panicRt(res.value.Annot, f.Src, line, col)
		return errNull("unreachable")
	default:
		return errNull("unknown VM status")
	}
}

////////////////////////////////////////////////////////////////////////////////
//                      SOURCE MAPPING (PC → (line, col))
////////////////////////////////////////////////////////////////////////////////

func (ip *Interpreter) sourcePosFromChunk(ch *Chunk, sr *SourceRef, pc int) (int, int) {
	// Single debug hook
	if DebuggingMode {
		dumpSourcePosDebug(ch, sr, pc)
	}

	src := ""
	if sr != nil {
		src = sr.Src
	}

	// Early fallback if we don't have enough info
	if ch == nil || sr == nil || sr.Spans == nil || len(ch.Marks) == 0 || src == "" {
		return 1, 1
	}

	// Pick the last mark with PC <= failing PC
	i := -1
	for j := range ch.Marks {
		if ch.Marks[j].PC <= pc {
			i = j
		} else {
			break
		}
	}
	if i < 0 {
		return 1, 1
	}

	tryPath := func(p NodePath) (int, int, bool) {
		for cut := len(p); cut >= 0; cut-- {
			sub := p[:cut]
			if sp, ok := sr.Spans.Get(sub); ok {
				line, col := offsetToLineCol(src, sp.StartByte)
				return line, col, true
			}
		}
		return 1, 1, false
	}

	// Try the best mark's path
	if line, col, ok := tryPath(ch.Marks[i].Path); ok {
		return line, col
	}

	// Walk earlier marks backwards
	for k := i - 1; k >= 0; k-- {
		if line, col, ok := tryPath(ch.Marks[k].Path); ok {
			return line, col
		}
	}

	return 1, 1
}

// withScope returns override if non-nil (use the call-site env for effects),
// otherwise it returns parent (the function's closure env).
func withScope(parent, override *Env) *Env {
	if override != nil {
		return override
	}
	return parent
}

func offsetToLineCol(src string, off int) (int, int) {
	if off < 0 {
		return 1, 1
	}
	line, col := 1, 1
	i := 0
	for i < len(src) && i < off {
		if src[i] == '\n' {
			line++
			col = 1
			i++
			continue
		}
		col++
		i++
	}
	return line, col
}

////////////////////////////////////////////////////////////////////////////////
//                 PRIVATE ADAPTERS: Callable / CallCtx impls
////////////////////////////////////////////////////////////////////////////////

type funCallable struct {
	f   *Fun
	doc string
}

func (c *funCallable) Arity() int { return len(c.f.Params) }
func (c *funCallable) ParamSpecs() []ParamSpec {
	ps := make([]ParamSpec, len(c.f.Params))
	for i := range c.f.Params {
		ps[i] = ParamSpec{Name: c.f.Params[i], Type: c.f.ParamTypes[i]}
	}
	return ps
}
func (c *funCallable) ReturnType() S    { return c.f.ReturnType }
func (c *funCallable) Doc() string      { return c.doc }
func (c *funCallable) ClosureEnv() *Env { return c.f.Env }

type callCtx struct {
	argEnv *Env
	scope  *Env
}

func (c *callCtx) Arg(name string) (Value, bool) { v, err := c.argEnv.Get(name); return v, err == nil }
func (c *callCtx) MustArg(name string) Value {
	if v, ok := c.Arg(name); ok {
		return v
	}
	fail("missing argument: " + name)
	return Null
}
func (c *callCtx) Env() *Env { return c.scope }

////////////////////////////////////////////////////////////////////////////////
//                             EMITTER (AST → BYTECODE)
////////////////////////////////////////////////////////////////////////////////

type emitter struct {
	ip        *Interpreter
	code      []uint32
	consts    []Value
	ctrlStack []ctrlCtx

	// Source mapping
	src   *SourceRef
	marks []PCMark
	path  NodePath
}

type ctrlCtx struct {
	isLoop     bool
	breakJumps []int
	contJumps  []int
}

func newEmitter(ip *Interpreter, src *SourceRef) *emitter {
	e := &emitter{ip: ip, src: src}
	if src != nil && len(src.PathBase) > 0 {
		e.path = append(e.path, src.PathBase...)
	}
	return e
}

// ---------------------- mark helpers (centralized) ---------------------------

// Emit a mark for an absolute AST path immediately before a failure-prone opcode.
// NOTE: Marks MUST be appended immediately before the instruction that can fail
// because of that path. Do NOT emit any other mark until that instruction.
func (e *emitter) markHereFor(abs NodePath) {
	e.marks = append(e.marks, PCMark{PC: e.here(), Path: append(NodePath(nil), abs...)})
}

// Mark the current node (rare; for node-level blame).
func (e *emitter) markSelf() { e.markHereFor(append(NodePath(nil), e.path...)) }

// Mark a direct child index under the current node.
func (e *emitter) markChild(childIdx int) {
	e.markHereFor(append(append(NodePath(nil), e.path...), childIdx))
}

// Wrappers that enforce "mark immediately before opcode" ordering.
func (e *emitter) emitWithMarkChild(op opcode, childIdx int, imm uint32) {
	e.markChild(childIdx)
	e.emit(op, imm)
}
func (e *emitter) callWithMarkChild(argc int, childIdx int) {
	e.markChild(childIdx)
	e.emit(opCall, uint32(argc))
}

// ----------------------------------------------------------------------------

func equalConst(a, b Value) bool {
	if a.Tag != b.Tag {
		return false
	}
	switch a.Tag {
	case VTNull:
		return true
	case VTBool:
		return a.Data.(bool) == b.Data.(bool)
	case VTInt:
		return a.Data.(int64) == b.Data.(int64)
	case VTNum:
		return a.Data.(float64) == b.Data.(float64)
	case VTStr:
		return a.Data.(string) == b.Data.(string)
	case VTArray, VTMap, VTFun, VTType, VTModule, VTHandle:
		// For const-pool purposes you usually don't intern compound values;
		// fall back to pointer/identity if you really need it:
		return &a == &b
	default:
		return false
	}
}

func (e *emitter) k(v Value) uint32 {
	for i := range e.consts {
		if equalConst(e.consts[i], v) { // <-- use strict equality here
			return uint32(i)
		}
	}
	e.consts = append(e.consts, v)
	return uint32(len(e.consts) - 1)
}
func (e *emitter) ks(s string) uint32         { return e.k(Str(s)) }
func (e *emitter) emit(op opcode, imm uint32) { e.code = append(e.code, pack(op, imm)) }
func (e *emitter) patch(at int, to int)       { e.code[at] = pack(uop(e.code[at]), uint32(to)) }
func (e *emitter) here() int                  { return len(e.code) }
func (e *emitter) chunk() *Chunk {
	return &Chunk{Code: e.code, Consts: e.consts, Marks: e.marks, Src: e.src}
}

func (e *emitter) pushBlockCtx() { e.ctrlStack = append(e.ctrlStack, ctrlCtx{isLoop: false}) }
func (e *emitter) pushLoopCtx()  { e.ctrlStack = append(e.ctrlStack, ctrlCtx{isLoop: true}) }
func (e *emitter) popCtx() ctrlCtx {
	i := len(e.ctrlStack) - 1
	c := e.ctrlStack[i]
	e.ctrlStack = e.ctrlStack[:i]
	return c
}
func (e *emitter) addBreakJump(at int) {
	for i := len(e.ctrlStack) - 1; i >= 0; i-- {
		if e.ctrlStack[i].isLoop {
			c := e.ctrlStack[i]
			c.breakJumps = append(c.breakJumps, at)
			e.ctrlStack[i] = c
			return
		}
	}
	i := len(e.ctrlStack) - 1
	c := e.ctrlStack[i]
	c.breakJumps = append(c.breakJumps, at)
	e.ctrlStack[i] = c
}
func (e *emitter) addContJump(at int) {
	for i := len(e.ctrlStack) - 1; i >= 0; i-- {
		if e.ctrlStack[i].isLoop {
			c := e.ctrlStack[i]
			c.contJumps = append(c.contJumps, at)
			e.ctrlStack[i] = c
			return
		}
	}
	i := len(e.ctrlStack) - 1
	c := e.ctrlStack[i]
	c.contJumps = append(c.contJumps, at)
	e.ctrlStack[i] = c
}

// helpers for loops/blocks persisting "last" value
func (e *emitter) preloadAssignToLast(lastName string) {
	e.emit(opLoadGlobal, e.ks("__assign_set"))
	// Preload the lvalue (("decl", lastName)) as AST handle. No call yet.
	e.emit(opConst, e.k(HandleVal("ast", S{"decl", lastName})))
}

func (e *emitter) saveLastAndJumpHead(head int) {
	e.emit(opCall, 2)
	e.emit(opPop, 0)
	e.emit(opJump, uint32(head))
}
func (e *emitter) patchGateAndSaveLast(jumps []int, gate int) {
	for _, at := range jumps {
		e.patch(at, gate)
	}
	e.emit(opCall, 2)
	e.emit(opPop, 0)
}

// Child path scaffolding
func (e *emitter) withChild(childIdx int, f func()) {
	e.path = append(e.path, childIdx)
	f()
	e.path = e.path[:len(e.path)-1]
}

// Builtin call (no automatic marks; callers place marks per plan).
func (e *emitter) callBuiltin(name string, args ...S) {
	e.emit(opLoadGlobal, e.ks(name))
	for _, a := range args {
		e.emitExpr(a)
	}
	e.emit(opCall, uint32(len(args)))
}

// callBuiltinV calls a Core builtin with constant Value arguments.
// Use this only when *all* arguments are constants you can encode now.
func (e *emitter) callBuiltinV(name string, args ...Value) {
	e.emit(opLoadGlobal, e.ks(name))
	for _, v := range args {
		e.emit(opConst, e.k(v))
	}
	e.emit(opCall, uint32(len(args)))
}

func (e *emitter) emitMakeFun(params S, retT S, bodyCarrier S, isOracle bool, examples S, basePath NodePath) {
	namesArr := make([]Value, 0, max(0, len(params)-1))
	for i := 1; i < len(params); i++ {
		p := params[i].(S)
		namesArr = append(namesArr, Str(p[1].(S)[1].(string)))
	}
	if len(retT) == 0 {
		retT = S{"id", "Any"}
	}
	e.emit(opLoadGlobal, e.ks("__make_fun"))
	for _, v := range namesArr {
		e.emit(opConst, e.k(v))
	}
	e.emit(opMakeArr, uint32(len(namesArr)))

	// Build the param types at runtime via ("type", …) so they capture env.
	typeCount := 0
	for i := 1; i < len(params); i++ {
		t := params[i].(S)[2].(S) // may be empty
		if len(t) == 0 {
			t = S{"id", "Any"}
		}
		e.emitExpr(S{"type", t})
		typeCount++
	}
	e.emit(opMakeArr, uint32(typeCount))

	// Return type (env-pinned) and BODY as AST handle
	e.emitExpr(S{"type", retT})
	e.emit(opConst, e.k(HandleVal("ast", bodyCarrier)))

	e.emit(opConst, e.k(Bool(isOracle)))
	e.emitExpr(examples)
	for _, idx := range basePath {
		e.emit(opConst, e.k(Int(int64(idx))))
	}
	e.emit(opMakeArr, uint32(len(basePath)))
	e.emit(opCall, 7)
}

func (e *emitter) emitFunBody(body S) {
	e.emitExpr(body)
	e.emit(opReturn, 0)
}

// Emit an expression node following the precise mark rules.
func (e *emitter) emitExpr(n S) {
	if len(n) == 0 {
		e.emit(opConst, e.k(Null))
		return
	}

	switch n[0].(string) {

	// ----- literals / ids -----
	case "int":
		e.emit(opConst, e.k(Int(n[1].(int64))))
	case "num":
		e.emit(opConst, e.k(Num(n[1].(float64))))
	case "str":
		e.emit(opConst, e.k(Str(n[1].(string))))
	case "bool":
		e.emit(opConst, e.k(Bool(n[1].(bool))))
	case "noop":
		e.emit(opConst, e.k(Null))
	case "null":
		e.emit(opConst, e.k(Null))

	case "id":
		// Identifier load can fail → mark the id right before opLoadGlobal.
		e.markSelf()
		e.emit(opLoadGlobal, e.ks(n[1].(string)))

	// ----- blocks -----
	case "block":
		e.pushBlockCtx()
		emitted := 0
		for j := 1; j < len(n); j++ {
			child := n[j].(S)
			if isNoopish(child) {
				continue
			}
			if emitted > 0 {
				e.emit(opPop, 0)
			}
			origIdx := j - 1 // original AST child index
			e.withChild(origIdx, func() { e.emitExpr(child) })
			emitted++
		}
		if emitted == 0 {
			e.emit(opConst, e.k(Null))
		}
		exit := e.here()
		ctx := e.popCtx()
		for _, at := range ctx.breakJumps {
			e.patch(at, exit)
		}
		for _, at := range ctx.contJumps {
			e.patch(at, exit)
		}

	// ----- flow: break / continue -----
	case "break":
		e.withChild(0, func() { e.emitExpr(n[1].(S)) })
		at := e.here()
		e.emit(opJump, 0)
		e.addBreakJump(at)
	case "continue":
		e.withChild(0, func() { e.emitExpr(n[1].(S)) })
		at := e.here()
		e.emit(opJump, 0)
		e.addContJump(at)

	// ----- unary -----
	case "unop":
		op := n[1].(string)
		if op == "?" {
			e.emit(opConst, e.k(errNull("postfix '?' invalid here")))
			return
		}
		e.withChild(1, func() { e.emitExpr(n[2].(S)) })
		// Mark operand right before opcode.
		switch op {
		case "not":
			e.emitWithMarkChild(opNot, 1, 0)
		case "-":
			e.emitWithMarkChild(opNeg, 1, 0)
		default:
			e.emit(opConst, e.k(errNull("unknown unary op")))
		}

	// ----- binary -----
	case "binop":
		op := n[1].(string)
		if op == "and" || op == "or" {
			// Short-circuit: mark tested subexpr at the gate.
			e.withChild(1, func() { e.emitExpr(n[2].(S)) })
			e.markChild(1)
			jf := e.here()
			e.emit(opJumpIfFalse, 0)

			// unified AND/OR short-circuit
			pre := func() { e.withChild(2, func() { e.emitExpr(n[3].(S)) }) } // RHS
			post := func() { e.emit(opConst, e.k(Bool(false))) }              // const false
			if op == "or" {
				pre, post = func() { e.emit(opConst, e.k(Bool(true))) }, pre // const true, then RHS
			}
			pre()
			jend := e.here()
			e.emit(opJump, 0)
			lother := e.here()
			e.patch(jf, lother)
			post()
			lend := e.here()
			e.patch(jend, lend)
			return
		}
		a, b := n[2].(S), n[3].(S)
		switch op {
		case "==":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opEq, 2, 0)
		case "!=":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opNe, 2, 0)
		case "+":
			e.emit(opLoadGlobal, e.ks("__plus"))
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.callWithMarkChild(2, 2)
		case "-":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opSub, 2, 0)
		case "*":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opMul, 2, 0)
		case "/":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opDiv, 2, 0)
		case "%":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opMod, 2, 0)
		case "<":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opLt, 2, 0)
		case "<=":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opLe, 2, 0)
		case ">":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opGt, 2, 0)
		case ">=":
			e.withChild(1, func() { e.emitExpr(a) })
			e.withChild(2, func() { e.emitExpr(b) })
			e.emitWithMarkChild(opGe, 2, 0)
		default:
			e.emit(opConst, e.k(errNull("unsupported operator")))
		}

	// ----- assignment -----
	case "assign":
		lhs := n[1].(S)
		opName := "__assign_set"
		switch lhs[0].(string) {
		case "decl", "darr", "dobj", "annot":
			opName = "__assign_def"
		}
		e.emit(opLoadGlobal, e.ks(opName))
		// LHS as a pure AST handle.
		e.emit(opConst, e.k(HandleVal("ast", lhs)))
		e.withChild(1, func() { e.emitExpr(n[2].(S)) })
		// Attribute assignment target errors to LHS: mark child #0 right before the CALL.
		e.callWithMarkChild(2, 0)

	case "decl":
		e.callBuiltinV("__assign_def", HandleVal("ast", n), Null)

	// ----- arrays / maps -----
	case "array":
		for i := 1; i < len(n); i++ {
			e.withChild(i-1, func() { e.emitExpr(n[i].(S)) })
		}
		e.emit(opMakeArr, uint32(len(n)-1))

	case "map":
		keys := S{"array"}
		vals := S{"array"}
		for i := 1; i < len(n); i++ {
			p := n[i].(S)
			keys = append(keys, p[1].(S))
			vals = append(vals, p[2].(S))
		}
		e.emit(opLoadGlobal, e.ks("__map_from"))
		for i := 1; i < len(keys); i++ {
			e.withChild(i-1, func() { e.withChild(0, func() { e.emitExpr(keys[i].(S)) }) })
		}
		e.emit(opMakeArr, uint32(len(keys)-1))
		for i := 1; i < len(vals); i++ {
			e.withChild(i-1, func() { e.withChild(1, func() { e.emitExpr(vals[i].(S)) }) })
		}
		e.emit(opMakeArr, uint32(len(vals)-1))
		e.emit(opCall, 2)

	// ----- property / index -----
	case "get":
		e.withChild(0, func() { e.emitExpr(n[1].(S)) })
		// Blame the property token (child #1) right before opGetProp.
		e.emitWithMarkChild(opGetProp, 1, e.ks(n[2].(S)[1].(string)))

	case "idx":
		e.withChild(0, func() { e.emitExpr(n[1].(S)) })
		e.withChild(1, func() { e.emitExpr(n[2].(S)) })
		// Blame the index expression (child #1) right before opGetIdx.
		e.emitWithMarkChild(opGetIdx, 1, 0)

	// ----- call -----
	case "call":
		// Evaluate callee once.
		e.withChild(0, func() { e.emitExpr(n[1].(S)) })

		argc := len(n) - 2
		if argc == 0 {
			// Zero-arg call: blame callee right before CALL 0.
			e.callWithMarkChild(0, 0)
			return
		}
		// Apply args one by one; blame each arg before its CALL 1.
		for i := 2; i < len(n); i++ {
			argIdx := i - 1
			e.withChild(argIdx, func() { e.emitExpr(n[i].(S)) })
			e.callWithMarkChild(1, argIdx)
		}
		return

	// ----- fun / oracle -----
	case "fun":
		// ("fun", params, ret, body) → body child index is 2
		absBase := append(append(NodePath(nil), e.path...), 2)
		e.emitMakeFun(n[1].(S), n[2].(S), n[3].(S), false, S{"null"}, absBase)
	case "oracle":
		e.withChild(2, func() {
			e.emitMakeFun(n[1].(S), n[2].(S), S{"oracle"}, true, n[3].(S), nil)
		})

	// ----- return -----
	case "return":
		e.withChild(0, func() { e.emitExpr(n[1].(S)) })
		e.markSelf()
		e.emit(opReturn, 0)

	// ----- if -----
	case "if":
		arms := n[1:]
		jends := []int{}
		hasElse := false
		if len(arms) > 0 {
			if last, ok := arms[len(arms)-1].(S); ok && last[0].(string) == "block" {
				hasElse = true
			}
		}
		limit := len(arms)
		if hasElse {
			limit--
		}
		for i := 0; i < limit; i++ {
			p := arms[i].(S) // ("pair", cond, thenBlock)
			// Emit condition; mark the condition node (pair child #0) at the gate.
			e.withChild(i, func() { e.withChild(0, func() { e.emitExpr(p[1].(S)) }) })
			condAbs := append(append(NodePath(nil), e.path...), i, 0)
			e.markHereFor(condAbs)
			jf := e.here()
			e.emit(opJumpIfFalse, 0)

			e.withChild(i, func() { e.withChild(1, func() { e.emitExpr(p[2].(S)) }) })
			jend := e.here()
			e.emit(opJump, 0)
			jends = append(jends, jend)
			e.patch(jf, e.here())
		}
		if hasElse {
			e.withChild(len(arms)-1, func() { e.emitExpr(arms[len(arms)-1].(S)) })
		} else {
			e.emit(opConst, e.k(Null))
		}
		tail := e.here()
		for _, at := range jends {
			e.patch(at, tail)
		}

	// ----- while -----
	case "while":
		cond := n[1].(S)
		body := n[2].(S)

		lastName := fmt.Sprintf("$last_%d", e.here())
		// Declare $last_* using an AST handle (no type building here).
		e.callBuiltinV("__assign_def",
			HandleVal("ast", S{"decl", lastName}),
			Null,
		)
		e.emit(opPop, 0)

		head := e.here()
		e.withChild(0, func() { e.emitExpr(cond) })
		// Mark the condition node right before the gate.
		e.markChild(0)
		jf := e.here()
		e.emit(opJumpIfFalse, 0)

		e.preloadAssignToLast(lastName)
		e.pushLoopCtx()
		e.withChild(1, func() { e.emitExpr(body) })
		loopCtx := e.popCtx()
		e.saveLastAndJumpHead(head)

		lcont := e.here()
		e.patchGateAndSaveLast(loopCtx.contJumps, lcont)
		e.emit(opJump, uint32(head))

		lbreak := e.here()
		e.patchGateAndSaveLast(loopCtx.breakJumps, lbreak)
		jEnd := e.here()
		e.emit(opJump, 0)

		end := e.here()
		e.patch(jf, end)
		e.patch(jEnd, end)

		e.emit(opLoadGlobal, e.ks(lastName))

	// ----- for -----
	case "for":
		target := n[1].(S)
		iterExpr := n[2].(S)
		body := n[3].(S)

		iterName := fmt.Sprintf("$iter_%d", e.here())
		// Declare the hidden iterator binding with an AST handle (not a Type).
		// We'll initialize it immediately with __to_iter(iterExpr) below.
		e.emit(opLoadGlobal, e.ks("__assign_def"))
		e.emit(opConst, e.k(HandleVal("ast", S{"decl", iterName})))

		// __to_iter(iterExpr); mark the iterExpr (child #1) at this call site.
		e.emit(opLoadGlobal, e.ks("__to_iter"))
		e.withChild(1, func() { e.emitExpr(iterExpr) })
		e.callWithMarkChild(1, 1) // __to_iter(iterExpr)
		e.emit(opCall, 2)         // assign_def(<AST decl>, iterator)
		e.emit(opPop, 0)

		tmpName := fmt.Sprintf("$tmp_%d", e.here())
		e.callBuiltinV("__assign_def", HandleVal("ast", S{"decl", tmpName}), Null)
		e.emit(opPop, 0)

		lastName := fmt.Sprintf("$last_%d", e.here())
		e.callBuiltinV("__assign_def", HandleVal("ast", S{"decl", lastName}), Null)
		e.emit(opPop, 0)

		head := e.here()

		// tmp = iter(Null)
		e.emit(opLoadGlobal, e.ks("__assign_set"))
		// lvalue as AST handle
		e.emit(opConst, e.k(HandleVal("ast", S{"decl", tmpName})))
		e.emit(opLoadGlobal, e.ks(iterName))
		e.emit(opConst, e.k(Null))
		e.emit(opCall, 1) // iter(Null)
		e.emit(opCall, 2) // assign_set(Type(tmp), result)
		e.emit(opPop, 0)

		// gate: __iter_should_stop(tmp)
		e.emit(opLoadGlobal, e.ks("__iter_should_stop"))
		e.emit(opLoadGlobal, e.ks(tmpName))
		e.emit(opCall, 1)
		jBody := e.here()
		e.emit(opJumpIfFalse, 0)
		jEnd := e.here()
		e.emit(opJump, 0)

		bodyStart := e.here()
		e.patch(jBody, bodyStart)

		e.preloadAssignToLast(lastName)

		assignName := "__assign_set"
		switch target[0].(string) {
		case "decl", "darr", "dobj", "annot":
			assignName = "__assign_def"
		}
		e.emit(opLoadGlobal, e.ks(assignName))
		e.emit(opConst, e.k(HandleVal("ast", target)))
		e.emit(opLoadGlobal, e.ks(tmpName))
		e.emit(opCall, 2)
		e.emit(opPop, 0)

		e.pushLoopCtx()
		e.withChild(2, func() { e.emitExpr(body) })
		loopCtx := e.popCtx()

		e.saveLastAndJumpHead(head)

		lcont := e.here()
		e.patchGateAndSaveLast(loopCtx.contJumps, lcont)
		e.emit(opJump, uint32(head))

		lbreak := e.here()
		e.patchGateAndSaveLast(loopCtx.breakJumps, lbreak)
		jToEnd := e.here()
		e.emit(opJump, 0)

		end := e.here()
		e.patch(jEnd, end)
		e.patch(jToEnd, end)

		e.emit(opLoadGlobal, e.ks(lastName))

	// ----- type / module / annot -----
	case "type":
		// Lower to: __type_from_ast(<handle carrying AST>), pinning env at runtime.
		e.emit(opLoadGlobal, e.ks("__type_from_ast"))
		e.emit(opConst, e.k(HandleVal("type-ast", n[1].(S))))
		// Blame the subject type node (child #0) at the call site.
		e.markChild(0)
		e.emit(opCall, 1)

	case "module":
		// Lower to: __make_module(nameExpr, <AST handle>, basePathArray)
		e.emit(opLoadGlobal, e.ks("__make_module"))
		e.withChild(0, func() { e.emitExpr(n[1].(S)) })
		// Pass the module body as a pure AST handle (no env pinning).
		e.emit(opConst, e.k(HandleVal("ast", n[2].(S))))
		absBase := append(append(NodePath(nil), e.path...), 1) // ("module", name, body) → body at child #1
		for _, idx := range absBase {
			e.emit(opConst, e.k(Int(int64(idx))))
		}
		e.emit(opMakeArr, uint32(len(absBase)))
		e.emit(opCall, 3)

	case "annot":
		text := n[1].(S)[1].(string)
		subj := n[2].(S)

		if isNoopish(subj) {
			e.emit(opConst, e.k(Null))
			return
		}

		// #(doc) (lhs = rhs)  ==>  lhs = #(doc) rhs
		if len(subj) > 0 && subj[0].(string) == "assign" {
			lhs := subj[1].(S)
			rhs := subj[2].(S)
			opName := "__assign_set"
			switch lhs[0].(string) {
			case "decl", "darr", "dobj", "annot":
				opName = "__assign_def"
			}
			e.emit(opLoadGlobal, e.ks(opName))
			// LHS as AST handle
			e.emit(opConst, e.k(HandleVal("ast", lhs)))
			e.emit(opLoadGlobal, e.ks("__annotate"))
			e.emit(opConst, e.k(Str(text)))
			e.withChild(1, func() { e.withChild(1, func() { e.emitExpr(rhs) }) })
			e.emit(opCall, 2) // __annotate
			// Attribute assignment errors to LHS (annot child #1 = assign, its child #0 = lhs).
			lhsAbs := append(append(NodePath(nil), e.path...), 1, 0)
			e.markHereFor(lhsAbs)
			e.emit(opCall, 2) // __assign_*
			return
		}

		// LVALUE-aware: #(doc) subj where subj ∈ {id,get,idx,decl}
		if len(subj) > 0 {
			switch subj[0].(string) {
			case "decl", "id", "get", "idx":
				opName := "__assign_set"
				if subj[0].(string) == "decl" {
					opName = "__assign_def"
				}
				e.emit(opLoadGlobal, e.ks(opName))
				// Subject as AST handle
				e.emit(opConst, e.k(HandleVal("ast", subj)))
				e.emit(opLoadGlobal, e.ks("__annotate"))
				e.emit(opConst, e.k(Str(text)))
				e.withChild(1, func() { e.emitExpr(subj) }) // build annotated RHS
				e.emit(opCall, 2)
				// Attribute to subject itself.
				e.markChild(1)
				e.emit(opCall, 2)
				return
			}
		}

		// default: #(doc) expr  ==>  __annotate(doc, expr)
		e.emit(opLoadGlobal, e.ks("__annotate"))
		e.emit(opConst, e.k(Str(text)))
		e.withChild(1, func() { e.emitExpr(subj) })
		e.emit(opCall, 2)

	default:
		e.emit(opConst, e.k(errNull(fmt.Sprintf("unknown AST tag: %s", n[0].(string)))))
	}
}

// Private panic/null helpers live in interpreter_ops.go.
=== END FILE: interpreter_exec.go ===

