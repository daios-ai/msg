=== BEGIN FILE: cmd/msg-lsp/core.go ===
// cmd/lsp/core.go
//
// ROLE: Shared infrastructure for the LSP server: transport helpers, server
//       state, text/position math, diagnostics, token/span utilities, and the
//       analysis pipeline (lex + parse + symbol extraction).
//
// What lives here
//   • Transport helpers for framed stdio (Content-Length) and convenience
//     send/notify wrappers (used by handlers).
//   • Server model:
//        - server: global state (open docs, mutex, interpreter handle).
//        - docState: per-document caches (raw text, line starts, tokens, AST,
//          span index, lightweight symbol table).
//   • Unicode/UTF-16 column math and byte↔position conversions consistent with
//     the LSP spec (positions are UTF-16 code units).
//   • Diagnostics plumbing: mapping lexer/parser errors to LSP ranges and
//     publishing them, including “incomplete” heuristics for on-type feedback.
//   • Token & span helpers: locate tokens at offsets, compute exact byte spans,
//     comment/annotation region detection for semantic tokens & folding.
//   • Analysis pipeline (`analyze`):
//        1) Lex (interactive), 2) Parse (interactive), 3) Collect top-level
//           symbols (no code execution), 4) Publish/clear diagnostics.
//     Results populate docState so feature handlers can be fast and side-effect-free.
//
// What does NOT live here
//   • No LSP feature handlers themselves (hover, completion, etc.).
//   • No business rules about how to format responses—handlers own that.
//   • No interpreter-driven execution of user code. (We only build tokens/AST
//     and extract symbols; see features.go for the optional, guarded lookup of
//     global/builtin metadata.)
//
// Why this separation
//   • Centralizes shared mechanics so features stay small and consistent.
//   • Makes unit testing of text math and analysis independent of UI features.
//
// Dependencies
//   • Relies on internal/mindscript lexer & parser (no VM/interpreter internals).
//   • Holds an *Interpreter pointer only for feature-level metadata queries;
//     core analysis itself does not execute user programs.

// cmd/lsp/core.go
package main

import (
	"bufio"
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"strings"
	"sync"
	"unicode/utf8"

	mindscript "github.com/DAIOS-AI/msg/internal/mindscript"
)

////////////////////////////////////////////////////////////////////////////////
// Transport (stdio framing) + send/notify
////////////////////////////////////////////////////////////////////////////////

var stdoutSink io.Writer = os.Stdout

func init() {
	// Silence unsolicited output during `go test` unless opted in.
	if strings.HasSuffix(os.Args[0], ".test") && os.Getenv("LSP_STDOUT") == "" {
		stdoutSink = io.Discard
	}
}

func readMsg(r *bufio.Reader) ([]byte, error) {
	var contentLen int
	for {
		line, err := r.ReadString('\n')
		if err != nil {
			return nil, err
		}
		line = strings.TrimRight(line, "\r\n")
		if line == "" {
			break
		}
		if i := strings.IndexByte(line, ':'); i >= 0 {
			key := strings.ToLower(strings.TrimSpace(line[:i]))
			val := strings.TrimSpace(line[i+1:])
			if key == "content-length" {
				_, _ = fmt.Sscanf(val, "%d", &contentLen)
			}
		}
	}
	if contentLen <= 0 {
		return nil, io.EOF
	}
	buf := make([]byte, contentLen)
	_, err := io.ReadFull(r, buf)
	return buf, err
}

func writeMsg(w io.Writer, v any) error {
	body, err := json.Marshal(v)
	if err != nil {
		return err
	}
	var b bytes.Buffer
	fmt.Fprintf(&b, "Content-Length: %d\r\n\r\n", len(body))
	b.Write(body)
	_, err = w.Write(b.Bytes())
	return err
}

func (s *server) sendResponse(id json.RawMessage, result any, respErr *ResponseError) {
	if respErr == nil && result == nil {
		rawNull := json.RawMessage([]byte("null"))
		_ = writeMsg(stdoutSink, Response{JSONRPC: "2.0", ID: id, Result: rawNull})
		return
	}
	_ = writeMsg(stdoutSink, Response{JSONRPC: "2.0", ID: id, Result: result, Error: respErr})
}

func (s *server) notify(method string, params any) {
	_ = writeMsg(stdoutSink, map[string]any{
		"jsonrpc": "2.0",
		"method":  method,
		"params":  params,
	})
}

////////////////////////////////////////////////////////////////////////////////
// Server state & document model
////////////////////////////////////////////////////////////////////////////////

type symbolDef struct {
	Name  string
	Kind  string // "let" | "fun" | "type"
	Range Range  // where it's declared
	Doc   string // first line, if available
	Sig   string // pretty signature for fun/oracle
}

// bindingDef: any assignment to a name (decl/id) anywhere in the file.
// Docs come uniformly from the VALUE's annotation wrapper if present.
type bindingDef struct {
	Name     string
	Range    Range // span of the defining identifier token
	DocFull  string
	DocFirst string
	Kind     string // "let" | "fun" | "oracle" | "type" | "param" | "" (best-effort)
	// Enriched info for hover/completion
	TypeNode []any  // synthesized/static type (vars/params) or declared return (fun/oracle/type)
	Sig      string // pretty signature for fun/oracle
}

type docState struct {
	uri     string
	text    string
	lines   []int // line start offsets (byte indices)
	symbols []symbolDef
	tokens  []mindscript.Token
	ast     mindscript.S
	spans   *mindscript.SpanIndex
	binds   []bindingDef // all bindings collected uniformly
}

type server struct {
	mu   sync.RWMutex
	docs map[string]*docState
	ip   *mindscript.Interpreter
}

func newServer() *server {
	ip, _ := mindscript.NewInterpreter()
	return &server{
		docs: make(map[string]*docState),
		ip:   ip,
	}
}

// snapshotDoc returns a consistent, read-only snapshot of a document.
func (s *server) snapshotDoc(uri string) *docState {
	s.mu.RLock()
	defer s.mu.RUnlock()
	d := s.docs[uri]
	if d == nil {
		return nil
	}
	cp := *d // shallow copy
	if d.lines != nil {
		cp.lines = append([]int(nil), d.lines...)
	}
	if d.tokens != nil {
		cp.tokens = append([]mindscript.Token(nil), d.tokens...)
	}
	if d.symbols != nil {
		cp.symbols = append([]symbolDef(nil), d.symbols...)
	}
	// ast/spans are immutable enough to share (spans is read-only).
	cp.ast = d.ast
	cp.spans = d.spans
	// binds is read-only after analyze
	if d.binds != nil {
		cp.binds = append([]bindingDef(nil), d.binds...)
	}
	return &cp
}

////////////////////////////////////////////////////////////////////////////////
// Text & UTF-16 helpers
////////////////////////////////////////////////////////////////////////////////

// CRLF-aware: treat "\r\n" as a single newline; store offsets at the byte *after* '\n'.
func lineOffsets(text string) []int {
	offs := []int{0}
	for i := 0; i < len(text); {
		if text[i] == '\r' {
			// skip lone \r (shouldn't happen often)
			i++
			continue
		}
		if text[i] == '\n' {
			offs = append(offs, i+1)
			i++
			continue
		}
		_, sz := utf8.DecodeRuneInString(text[i:])
		if sz <= 0 {
			sz = 1
		}
		i += sz
	}
	return offs
}

func toU16(r rune) int {
	if r < 0x10000 {
		return 1
	}
	return 2
}

func posToOffset(lines []int, p Position, text string) int {
	if p.Line < 0 {
		return 0
	}
	if p.Line >= len(lines) {
		return len(text)
	}
	i := lines[p.Line]
	need := p.Character // in UTF-16 units
	for i < len(text) && need > 0 {
		r, sz := utf8.DecodeRuneInString(text[i:])
		if r == '\r' { // ignore CR in column math
			i += sz
			continue
		}
		if r == '\n' {
			break
		}
		need -= toU16(r)
		i += sz
	}
	return i
}

func offsetToPos(lines []int, off int, text string) Position {
	if off < 0 {
		off = 0
	}
	if off > len(text) {
		off = len(text)
	}
	i, j := 0, len(lines)
	for i+1 < j {
		m := (i + j) / 2
		if lines[m] <= off {
			i = m
		} else {
			j = m
		}
	}
	u16 := 0
	for k := lines[i]; k < off && k < len(text); {
		r, sz := utf8.DecodeRuneInString(text[k:])
		if r == '\r' { // ignore CR
			k += sz
			continue
		}
		if r == '\n' {
			break
		}
		u16 += toU16(r)
		k += sz
	}
	return Position{Line: i, Character: u16}
}

func makeRange(lines []int, start, end int, text string) Range {
	return Range{
		Start: offsetToPos(lines, start, text),
		End:   offsetToPos(lines, end, text),
	}
}

// Engine gives us byte columns (not UTF-16). Clamp within the line.
func byteColToOffset(lines []int, line0, byteCol int, text string) int {
	if line0 < 0 {
		line0 = 0
	}
	if line0 >= len(lines) {
		return len(text)
	}
	start := lines[line0]
	end := len(text)
	if line0+1 < len(lines) {
		end = lines[line0+1]
	}
	off := start + byteCol
	if off < start {
		off = start
	}
	if off > end {
		off = end
	}
	return off
}

// UTF-16 code-unit length of a string slice (for semantic tokens).
func u16Len(s string) int {
	n := 0
	for _, r := range s {
		if r < 0x10000 {
			n++
		} else {
			n += 2
		}
	}
	return n
}

// hasValidSpan reports whether the lexer provided concrete byte offsets.
// Used for ANNOTATION tokens which must have StartByte/EndByte or be ignored.
func hasValidSpan(t mindscript.Token, textLen int) bool {
	return t.StartByte >= 0 && t.EndByte >= t.StartByte && t.EndByte <= textLen
}

////////////////////////////////////////////////////////////////////////////////
// Diagnostics helpers
////////////////////////////////////////////////////////////////////////////////

func (s *server) clearDiagnostics(uri string) {
	s.notify("textDocument/publishDiagnostics", PublishDiagnosticsParams{
		URI:         uri,
		Diagnostics: []Diagnostic{},
	})
}

func (s *server) publishError(doc *docState, err error) {
	// REPL-friendly: don't nag on incomplete constructs.
	if e, ok := err.(*mindscript.Error); ok {
		// Prefer the engine’s explicit “incomplete” signal.
		if e.Kind == mindscript.DiagIncomplete {
			s.clearDiagnostics(doc.uri)
			return
		}
		// Back-compat: older lexers/parsers may still surface text hints.
		if e.Kind == mindscript.DiagParse || e.Kind == mindscript.DiagLex {
			msg := strings.ToLower(e.Msg)
			if strings.Contains(msg, "incomplete") || strings.Contains(msg, "unterminated") {
				s.clearDiagnostics(doc.uri)
				return
			}
		}
	}

	line, col := 0, 0
	code := ""
	if e, ok := err.(*mindscript.Error); ok {
		line, col = e.Line, e.Col // 1-based positions from MindScript
		switch e.Kind {
		case mindscript.DiagParse:
			code = "PARSE"
		case mindscript.DiagLex:
			code = "LEX"
		default:
		}
	}
	if line > 0 {
		line-- // engine lines are 1-based
	}
	start := byteColToOffset(doc.lines, line, col, doc.text)
	end := start

	// Try to expand to a token on that exact start position.
	if len(doc.tokens) > 0 {
		for _, t := range doc.tokens {
			if t.Line == line+1 && t.Col == col {
				ts := byteColToOffset(doc.lines, t.Line-1, t.Col, doc.text)
				te := ts + len(t.Lexeme)
				start, end = ts, te
				break
			}
		}
	}
	if end <= start {
		if start < len(doc.text) {
			// Highlight the next rune when inside the buffer.
			_, sz := utf8.DecodeRuneInString(doc.text[start:])
			if sz <= 0 {
				sz = 1
			}
			end = start + sz
		} else if start > 0 {
			// At end-of-buffer: highlight the previous rune.
			_, sz := utf8.DecodeLastRuneInString(doc.text[:start])
			if sz <= 0 {
				sz = 1
			}
			start = start - sz
			end = start + sz
		}
	}

	s.notify("textDocument/publishDiagnostics", PublishDiagnosticsParams{
		URI: doc.uri,
		Diagnostics: []Diagnostic{{
			Range:    makeRange(doc.lines, start, end, doc.text),
			Severity: 1,
			Code:     code,
			Source:   "mindscript",
			Message:  err.Error(),
		}},
	})
}

////////////////////////////////////////////////////////////////////////////////
// Token & span helpers
////////////////////////////////////////////////////////////////////////////////

func tokenName(t mindscript.Token) string {
	if s, ok := t.Literal.(string); ok {
		return s
	}
	return t.Lexeme
}

// Prefer exact lexer byte spans; fallback to line-local search.
func tokenSpan(doc *docState, t mindscript.Token) (start, end int) {
	// NEW: exact byte spans from the lexer if present.
	if t.StartByte >= 0 && t.EndByte >= t.StartByte && t.EndByte <= len(doc.text) {
		return t.StartByte, t.EndByte
	}

	if t.Line < 1 || t.Line > len(doc.lines) {
		return 0, 0
	}
	lineStart := doc.lines[t.Line-1]
	lineEnd := len(doc.text)
	if t.Line < len(doc.lines) {
		lineEnd = doc.lines[t.Line]
	}
	line := doc.text[lineStart:lineEnd]

	cand := t.Col
	if cand < 0 {
		cand = 0
	}
	if cand > len(line) {
		cand = len(line)
	}
	try := func(at int) (int, int, bool) {
		if at < 0 {
			at = 0
		}
		if at+len(t.Lexeme) > len(line) {
			return 0, 0, false
		}
		if line[at:at+len(t.Lexeme)] == t.Lexeme {
			s := lineStart + at
			return s, s + len(t.Lexeme), true
		}
		return 0, 0, false
	}
	if s, e, ok := try(cand); ok {
		return s, e
	}
	if s, e, ok := try(cand - 1); ok {
		return s, e
	}
	const window = 8
	from := cand - window
	if from < 0 {
		from = 0
	}
	if idx := strings.Index(line[from:], t.Lexeme); idx >= 0 {
		s := lineStart + from + idx
		return s, s + len(t.Lexeme)
	}
	s := lineStart + t.Col
	e := s + len(t.Lexeme)
	if s < 0 {
		s = 0
	}
	if e > len(doc.text) {
		e = len(doc.text)
	}
	if e < s {
		e = s
	}
	return s, e
}

// tokenAtOffset returns the token index and span whose lexeme covers [off].
func tokenAtOffset(doc *docState, off int) (idx int, t mindscript.Token, start, end int, ok bool) {
	for i, tk := range doc.tokens {
		s, e := tokenSpan(doc, tk)
		if off >= s && off < e {
			return i, tk, s, e, true
		}
	}
	return -1, mindscript.Token{}, 0, 0, false
}

// Use SpanIndex to build a Range from a NodePath.
func rangeFromPath(doc *docState, p mindscript.NodePath) (Range, bool) {
	if doc.spans == nil {
		return Range{}, false
	}
	sp, ok := doc.spans.Get(p)
	if !ok {
		return Range{}, false
	}
	return makeRange(doc.lines, sp.StartByte, sp.EndByte, doc.text), true
}

func findSymbol(doc *docState, name string) (symbolDef, bool) {
	for _, s := range doc.symbols {
		if s.Name == name {
			return s, true
		}
	}
	return symbolDef{}, false
}

// -------- Annotation & binding helpers (no special-casing) --------

// annotText returns (baseNode, mergedAnnotationText, ok) without mutating the node.
func annotText(n []any) ([]any, string, bool) {
	cur := n
	var parts []string
	for len(cur) >= 3 {
		if tag, _ := cur[0].(string); tag != "annot" {
			break
		}
		if child, ok := cur[1].([]any); ok && len(child) >= 2 && child[0] == "str" {
			if s, _ := child[1].(string); s != "" {
				parts = append(parts, s)
			}
		}
		base, _ := cur[2].([]any)
		cur = base
	}
	if len(parts) == 0 {
		return n, "", false
	}
	return cur, strings.Join(parts, "\n"), true
}

func firstLine(s string) string {
	if i := strings.IndexByte(s, '\n'); i >= 0 {
		return strings.TrimSpace(s[:i])
	}
	return strings.TrimSpace(s)
}

func indexOfToken(toks []mindscript.Token, tk mindscript.Token) int {
	for i, t := range toks {
		if t == tk {
			return i
		}
	}
	return -1
}

// wordAt: prefer token-based match; fallback to ASCII scan if needed.
func wordAt(doc *docState, pos Position) (string, Range) {
	off := posToOffset(doc.lines, pos, doc.text)
	if off < 0 || off > len(doc.text) {
		return "", Range{}
	}
	for _, t := range doc.tokens {
		// FIX: only IDs are symbol names; TYPE is a keyword.
		if t.Type != mindscript.ID {
			continue
		}
		start, end := tokenSpan(doc, t)
		if off >= start && off < end {
			name := tokenName(t)
			return name, makeRange(doc.lines, start, end, doc.text)
		}
	}
	// fallback: ASCII-ish word scan
	isIdent := func(b byte) bool {
		return b == '_' ||
			(b >= 'a' && b <= 'z') || (b >= 'A' && b <= 'Z') ||
			(b >= '0' && b <= '9')
	}
	i, j := off, off
	for i > 0 && isIdent(doc.text[i-1]) {
		i--
	}
	for j < len(doc.text) && isIdent(doc.text[j]) {
		j++
	}
	if i < j {
		return strings.TrimSpace(doc.text[i:j]), makeRange(doc.lines, i, j, doc.text)
	}
	return "", Range{}
}

////////////////////////////////////////////////////////////////////////////////
// Shared keyword/type helpers (used by hover/completion/semTokens)
////////////////////////////////////////////////////////////////////////////////

func isKeywordButNotType(tt mindscript.TokenType) bool {
	switch tt {
	case mindscript.AND, mindscript.OR, mindscript.NOT,
		mindscript.LET, mindscript.DO, mindscript.END, mindscript.RETURN, mindscript.BREAK, mindscript.CONTINUE,
		mindscript.IF, mindscript.THEN, mindscript.ELIF, mindscript.ELSE,
		mindscript.FUNCTION, mindscript.ORACLE,
		mindscript.FOR, mindscript.IN, mindscript.FROM, mindscript.WHILE,
		// FIX: 'type' keyword should be colored as a keyword, not a type identifier.
		mindscript.TYPECONS, mindscript.TYPE, mindscript.ENUM,
		mindscript.NULL:
		return true
	default:
		return false
	}
}

var builtinTypeDocs = map[string]string{
	"Any":  "Top type; any value.",
	"Null": "Null value (absence).",
	"Bool": "Boolean type (true/false).",
	"Int":  "64-bit signed integer.",
	"Num":  "64-bit IEEE-754 float.",
	"Str":  "Unicode string.",
	"Type": "Type descriptor value.",
}

// semantic tokens type legend index (handlers will read this)
var semTypes = map[string]int{
	"keyword":  0,
	"function": 1,
	"type":     2,
	"variable": 3,
	"property": 4,
	"string":   5,
	"number":   6,
	"comment":  7,
	"bracket":  8,
}

func overlaps(a, b [2]int) bool { return a[0] < b[1] && b[0] < a[1] }

// comment/annotation spans used by semantic tokens & folding.
func commentSpans(doc *docState) [][2]int {
	spans := [][2]int{}
	if doc == nil {
		return spans
	}
	// Source of truth: lexer ANNOTATION tokens only, and only when they carry a valid span.
	for _, tk := range doc.tokens {
		if tk.Type != mindscript.ANNOTATION {
			continue
		}
		if !hasValidSpan(tk, len(doc.text)) {
			continue
		}
		s, e := tk.StartByte, tk.EndByte
		if e > s {
			spans = append(spans, [2]int{s, e})
		}
	}
	return spans
}

////////////////////////////////////////////////////////////////////////////////
// Definition heuristics & symbol formatting
////////////////////////////////////////////////////////////////////////////////

// defRangeByTokens: heuristic: let <name> … OR <name> = … (same or next line)
func defRangeByTokens(doc *docState, name string) (Range, bool) {
	toks := doc.tokens
	for i := 0; i < len(toks); i++ {
		t := toks[i]
		if t.Type != mindscript.ID || tokenName(t) != name {
			continue
		}
		// let <name> …
		if i >= 1 && toks[i-1].Type == mindscript.LET && toks[i-1].Line == t.Line {
			s, e := tokenSpan(doc, t)
			return makeRange(doc.lines, s, e, doc.text), true
		}
		if i >= 2 && toks[i-2].Type == mindscript.LET && toks[i-2].Line == t.Line {
			s, e := tokenSpan(doc, t)
			return makeRange(doc.lines, s, e, doc.text), true
		}
		// <name> = … (same line)
		found := false
		line := t.Line
		for j := i + 1; j < len(toks) && toks[j].Line == line; j++ {
			if toks[j].Type == mindscript.ASSIGN {
				found = true
				break
			}
		}
		// spill to next line: <name> \n =
		if !found {
			for j := i + 1; j < len(toks); j++ {
				if toks[j].Line > line+1 {
					break
				}
				if toks[j].Type == mindscript.ASSIGN {
					found = true
					break
				}
			}
		}
		if found {
			s, e := tokenSpan(doc, t)
			return makeRange(doc.lines, s, e, doc.text), true
		}
	}
	return Range{}, false
}

// formatFunSig builds a pretty signature from a ("fun", ...) AST node.
func formatFunSig(name string, fun []any) string {
	if len(fun) < 3 {
		return name + "() -> Any"
	}
	ps, _ := fun[1].([]any)
	var parts []string
	if len(ps) > 0 && ps[0] == "array" {
		for i := 1; i < len(ps); i++ {
			p, _ := ps[i].([]any) // ("pair"| "pair!", ("id", name), typeS)
			if len(p) >= 3 && (p[0] == "pair" || p[0] == "pair!") {
				idNode, _ := p[1].([]any)
				nameStr := "_"
				if len(idNode) >= 2 && idNode[0] == "id" {
					if s, ok := idNode[1].(string); ok {
						nameStr = s
					}
				}
				if tS, ok := p[2].([]any); ok {
					parts = append(parts, fmt.Sprintf("%s: %s", nameStr, mindscript.FormatType(tS)))
				} else {
					parts = append(parts, nameStr+": Any")
				}
			}
		}
	}
	ret := "Any"
	if rt, ok := fun[2].([]any); ok {
		ret = mindscript.FormatType(rt)
	}
	return fmt.Sprintf("%s(%s) -> %s", name, strings.Join(parts, ", "), ret)
}

////////////////////////////////////////////////////////////////////////////////
// Analysis (lex + parse + symbol extraction) — publishes diagnostics via notify
////////////////////////////////////////////////////////////////////////////////

// analyze lexes, parses, and refreshes the per-doc caches used by features.
// It fills: doc.tokens, doc.ast (when parse succeeds), and doc.symbols (top-level defs).
func (s *server) analyze(doc *docState) {
	// 1) Lex (interactive is fine; the tests use valid input)
	lx := mindscript.NewLexerInteractive(doc.text)
	toks, err := lx.Scan()
	if err != nil {
		// Try to salvage tokens up to the error position so semantic tokens
		// still color the prefix.
		if e, ok := err.(*mindscript.Error); ok && e.Kind == mindscript.DiagLex {
			off := byteColToOffset(doc.lines, e.Line-1, e.Col-1, doc.text)
			if off < 0 {
				off = 0
			}
			if off > len(doc.text) {
				off = len(doc.text)
			}
			// Re-lex the prefix only; this should succeed.
			px := mindscript.NewLexerInteractive(doc.text[:off])
			ptoks, pErr := px.Scan()
			if pErr == nil {
				if n := len(ptoks); n > 0 && ptoks[n-1].Type == mindscript.EOF {
					ptoks = ptoks[:n-1]
				}
				doc.tokens = ptoks
			} else {
				// If even the prefix fails, leave tokens as-is (keep previous coloring).
			}
		}
		doc.symbols = nil
		doc.ast = nil
		s.publishError(doc, err)
		return
	}
	// Drop the terminal EOF token for downstream convenience.
	if n := len(toks); n > 0 && toks[n-1].Type == mindscript.EOF {
		toks = toks[:n-1]
	}
	doc.tokens = toks

	// 2) Parse (interactive) with exact spans for every node.
	//    Interactive mode yields DiagIncomplete for half-typed code.
	ast, spans, err := mindscript.ParseSExprInteractiveWithSpans(doc.text)
	if err != nil {
		// Parsing failed (possibly incomplete). Keep tokens, clear AST/symbols.
		// IMPORTANT: preserve last-good spans so folding/range features remain stable.
		doc.ast = nil
		doc.symbols = nil
		// doc.spans is intentionally NOT touched here.
		s.publishError(doc, err)
		return
	}
	doc.ast = ast
	doc.spans = spans

	// Uniform: collect all bindings + docs (any assignment anywhere).
	doc.binds = collectBindings(doc)

	// 3) Rebuild top-level symbols (alpha/beta/etc.). This does NOT execute user code.
	doc.symbols = collectTopLevelSymbols(doc)

	// 4) Success: clear any previous diagnostics.
	s.clearDiagnostics(doc.uri)
}

// ---------- Lightweight static type synthesis (no execution) ----------
// We represent types as the same AST nodes used in function signatures:
//   ("id","Int"), ("array", T), ("map", ("pair", ("str","k"), T), ...), ("unop","?", T)
// and pretty-print with mindscript.FormatType.

// typeID builds a leaf type like Int/Num/Str/Any.
func typeID(name string) []any { return []any{"id", name} }

// formatTypeNode -> human string (falls back to "Any" on nil/unknown)
func formatTypeNode(t []any) string {
	if len(t) == 0 {
		return "Any"
	}
	return mindscript.FormatType(t)
}

// numericSuper: Int + Num -> Num; Int + Int -> Int; else Any.
func numericSuper(a, b []any) []any {
	as, bs := formatTypeNode(a), formatTypeNode(b)
	if as == "Num" || bs == "Num" {
		return typeID("Num")
	}
	if as == "Int" && bs == "Int" {
		return typeID("Int")
	}
	// treat unknowns conservatively
	if as == "Any" || bs == "Any" {
		return typeID("Any")
	}
	return typeID("Any")
}

// commonSuper for conditionals/merges: a == b -> a; Int vs Num -> Num; else Any.
func commonSuper(a, b []any) []any {
	as, bs := formatTypeNode(a), formatTypeNode(b)
	if as == bs {
		return a
	}
	// numeric widening
	if (as == "Int" && bs == "Num") || (as == "Num" && bs == "Int") {
		return typeID("Num")
	}
	return typeID("Any")
}

// findLocalFunRetType returns the declared return type node of a top-level fun/oracle named 'name'.
func findLocalFunRetType(doc *docState, name string) ([]any, bool) {
	if doc == nil || doc.ast == nil || len(doc.ast) == 0 {
		return nil, false
	}
	root := doc.ast
	if root[0] != "block" {
		return nil, false
	}
	for i := 1; i < len(root); i++ {
		n, ok := root[i].([]any)
		if !ok || len(n) < 3 || n[0] != "assign" {
			continue
		}
		lhs, _ := n[1].([]any)
		rhs, _ := n[2].([]any)
		if len(lhs) >= 2 && (lhs[0] == "decl" || lhs[0] == "id") {
			if nm, _ := lhs[1].(string); nm == name {
				base, _, _ := annotText(rhs)
				if len(base) >= 3 && (base[0] == "fun" || base[0] == "oracle") {
					// fun/oracle layout: ("fun", params, ret, body) / ("oracle", params, outType, source)
					if tnode, ok := base[2].([]any); ok {
						// oracle calls return nullable; the declared *output* type lives here.
						if base[0] == "oracle" {
							return []any{"unop", "?", tnode}, true
						}
						return tnode, true
					}
				}
			}
		}
	}
	return nil, false
}

// rhsForBinding locates the RHS node for a binding by matching the LHS span to b.Range.
func rhsForBinding(doc *docState, b bindingDef) ([]any, bool) {
	if doc == nil || doc.ast == nil || doc.spans == nil {
		return nil, false
	}
	// Convert binding range start/end to byte offsets
	start := posToOffset(doc.lines, b.Range.Start, doc.text)
	end := posToOffset(doc.lines, b.Range.End, doc.text)

	var found []any
	var walk func(node []any, path mindscript.NodePath)
	walk = func(node []any, path mindscript.NodePath) {
		if found != nil {
			return
		}
		if len(node) >= 3 && node[0] == "assign" {
			lhs, _ := node[1].([]any)
			rhs, _ := node[2].([]any)
			_ = lhs
			// span for the LHS child
			lhsPath := append(append(mindscript.NodePath{}, path...), 0)
			if sp, ok := doc.spans.Get(lhsPath); ok {
				if sp.StartByte == start && sp.EndByte == end {
					found = rhs
					return
				}
			}
		}
		for i := 1; i < len(node); i++ {
			if ch, ok := node[i].([]any); ok {
				walk(ch, append(path, i-1))
			}
		}
	}
	walk(doc.ast, mindscript.NodePath{})
	if found == nil {
		return nil, false
	}
	return found, true
}

// inferExprType synthesizes a best-effort type for a value expression.
func inferExprType(doc *docState, n []any) []any {
	if len(n) == 0 {
		return typeID("Any")
	}
	tag, _ := n[0].(string)
	switch tag {
	case "str":
		return typeID("Str")
	case "int":
		return typeID("Int")
	case "num":
		return typeID("Num")
	case "bool":
		return typeID("Bool")
	case "null":
		return typeID("Null")

	case "array":
		// ("array", e1, e2, ...)
		if len(n) == 1 {
			return []any{"array", typeID("Any")}
		}
		elem := typeID("Any")
		for i := 1; i < len(n); i++ {
			if ch, ok := n[i].([]any); ok {
				elem = commonSuper(elem, inferExprType(doc, ch))
			}
		}
		return []any{"array", elem}

	case "map":
		// Build an open-map type with fields we see: { key: T, ... }
		out := []any{"map"}
		for i := 1; i < len(n); i++ {
			p, ok := n[i].([]any)
			if !ok || len(p) < 3 {
				continue
			}
			if p[0] != "pair" && p[0] != "pair!" {
				continue
			}
			keyNode, _ := p[1].([]any)
			valNode, _ := p[2].([]any)
			ks := ""
			if len(keyNode) >= 2 && keyNode[0] == "str" {
				ks, _ = keyNode[1].(string)
			}
			t := inferExprType(doc, valNode)
			out = append(out, []any{"pair", []any{"str", ks}, t})
		}
		return out

	case "call":
		// ("call", callee, arg1, ...)
		if len(n) >= 2 {
			callee, _ := n[1].([]any)
			// id callee?
			if len(callee) >= 2 && callee[0] == "id" {
				name, _ := callee[1].(string)
				// Prefer local fun/oracle signature
				if rt, ok := findLocalFunRetType(doc, name); ok {
					return rt
				}
			}
		}
		return typeID("Any")

	case "get":
		// ("get", obj, ("str", name))
		if len(n) >= 3 {
			objNode, _ := n[1].([]any)
			objT := inferExprType(doc, objNode)
			key := ""
			if ks, ok := n[2].([]any); ok && len(ks) >= 2 && ks[0] == "str" {
				key, _ = ks[1].(string)
			}
			// If objT is a map type with that field, return the field type.
			if len(objT) > 0 && objT[0] == "map" {
				for i := 1; i < len(objT); i++ {
					if pr, ok := objT[i].([]any); ok && len(pr) >= 3 && (pr[0] == "pair" || pr[0] == "pair!") {
						if k, ok := pr[1].([]any); ok && len(k) >= 2 && k[0] == "str" {
							if nm, _ := k[1].(string); nm == key {
								if tv, ok := pr[2].([]any); ok {
									return tv
								}
							}
						}
					}
				}
			}
		}
		return typeID("Any")

	case "idx":
		// ("idx", obj, index)
		if len(n) >= 2 {
			objNode, _ := n[1].([]any)
			objT := inferExprType(doc, objNode)
			if len(objT) >= 2 && objT[0] == "array" {
				if t, ok := objT[1].([]any); ok {
					return t
				}
			}
		}
		return typeID("Any")

	case "binop":
		// ("binop", op, lhs, rhs)
		if len(n) >= 4 {
			op, _ := n[1].(string)
			lhsNode, _ := n[2].([]any)
			rhsNode, _ := n[3].([]any)
			lhs := inferExprType(doc, lhsNode)
			rhs := inferExprType(doc, rhsNode)
			switch op {
			case "+", "-", "*", "%":
				return numericSuper(lhs, rhs)
			case "/":
				// Int/Int -> Int else Num (if either Num -> Num)
				as, bs := formatTypeNode(lhs), formatTypeNode(rhs)
				if as == "Int" && bs == "Int" {
					return typeID("Int")
				}
				if as == "Num" || bs == "Num" {
					return typeID("Num")
				}
				return typeID("Any")
			case "==", "!=":
				return typeID("Bool")
			case "<", "<=", ">", ">=":
				return typeID("Bool")
			case "and", "or", "&", "|", "^", "<<", ">>":
				if op == "and" || op == "or" {
					return typeID("Bool")
				}
				return typeID("Int")
			}
		}
		return typeID("Any")

	case "unop":
		// ("unop", op, rhs)
		if len(n) >= 3 {
			op, _ := n[1].(string)
			rNode, _ := n[2].([]any)
			r := inferExprType(doc, rNode)
			switch op {
			case "-":
				rs := formatTypeNode(r)
				if rs == "Int" || rs == "Num" {
					return r
				}
				return typeID("Any")
			case "not":
				return typeID("Bool")
			case "?":
				// nullable postfix on values shows up as unop "?" too (when used in type positions).
				return []any{"unop", "?", r}
			}
		}
		return typeID("Any")

	case "if":
		// ("if", ("pair", cond, then), ..., else?)
		// merge then/else result types
		var t []any
		for i := 1; i < len(n); i++ {
			arm, _ := n[i].([]any)
			if len(arm) == 0 {
				continue
			}
			if arm[0] == "pair" && len(arm) >= 3 {
				thenBlk, _ := arm[2].([]any)
				t = commonSuper(t, inferExprType(doc, thenBlk))
			} else {
				// else tail (single block)
				t = commonSuper(t, inferExprType(doc, arm))
			}
		}
		if len(t) == 0 {
			return typeID("Any")
		}
		return t
	}
	return typeID("Any")
}

// ---------- Uniform binding collection (no top-level specialness) ----------

// collectBindings walks the AST and records every binding of the form:
//
//	("assign", ("decl" | "id" | "darr" | "dobj", ...), value)
//
// It extracts docs from the VALUE's annotation wrapper if present, for all kinds.
func collectBindings(doc *docState) []bindingDef {
	var out []bindingDef
	if doc == nil || doc.ast == nil {
		return out
	}

	var push func(name string, rhs []any, rng Range)
	push = func(name string, rhs []any, rng Range) {
		if name == "" {
			return
		}
		// Best-effort kind + doc + type/sig: inspect rhs tag (after stripping annot).
		base, txt, _ := annotText(rhs)
		kind := ""
		var tnode []any
		sig := ""
		if len(base) > 0 {
			switch tag := base[0].(string); tag {
			case "fun":
				kind = "fun"
				// declared return type lives at base[2]
				if rt, ok := base[2].([]any); ok {
					tnode = rt
				}
				// produce pretty signature now that we have the name
				sig = formatFunSig(name, base)
			case "oracle":
				kind = "oracle"
				if rt, ok := base[2].([]any); ok {
					tnode = []any{"unop", "?", rt}
				}
				sig = formatFunSig(name, base)
			case "type":
				kind = "type"
			default:
				kind = "let"
			}
		}
		if len(tnode) == 0 {
			// Values (non fun/oracle/type): synthesize a type
			tnode = inferExprType(doc, base)
		}
		out = append(out, bindingDef{
			Name:     name,
			Range:    rng,
			DocFull:  txt,
			DocFirst: firstLine(txt),
			Kind:     kind,
			TypeNode: tnode,
			Sig:      sig,
		})
	}

	// name + exact id/decl path for SpanIndex → Range
	type nameAt struct {
		Name string
		Path mindscript.NodePath
	}

	var collectPat func(pat []any, base mindscript.NodePath, acc *[]nameAt)
	collectPat = func(pat []any, base mindscript.NodePath, acc *[]nameAt) {
		if len(pat) == 0 {
			return
		}
		tag, _ := pat[0].(string)
		switch tag {
		case "decl":
			if len(pat) >= 2 {
				if n, _ := pat[1].(string); n != "" {
					// Use the decl node span for the identifier
					*acc = append(*acc, nameAt{Name: n, Path: append(mindscript.NodePath{}, base...)})
				}
			}
		case "id":
			if len(pat) >= 2 {
				if n, _ := pat[1].(string); n != "" {
					// Path points at the ("id", name) node itself
					*acc = append(*acc, nameAt{Name: n, Path: append(mindscript.NodePath{}, base...)})
				}
			}
		case "darr":
			for i := 1; i < len(pat); i++ {
				if ch, ok := pat[i].([]any); ok {
					collectPat(ch, append(append(mindscript.NodePath{}, base...), i-1), acc)
				}
			}
		case "dobj":
			for i := 1; i < len(pat); i++ {
				if pair, ok := pat[i].([]any); ok && len(pair) >= 3 && (pair[0] == "pair" || pair[0] == "pair!") {
					if sub, ok := pair[2].([]any); ok {
						// descend into value position of the pair: child index 2 → path component (2-1)=1
						collectPat(sub, append(append(mindscript.NodePath{}, base...), i-1, 1), acc)
					}
				}
			}
		default:
			// ignore other lvalues (get/idx) in this minimal pass
		}
	}

	// Walk with path tracking so we can compute param ranges via SpanIndex.
	var walk func(n []any, path mindscript.NodePath)
	walk = func(n []any, path mindscript.NodePath) {
		if len(n) == 0 {
			return
		}
		tag, _ := n[0].(string)
		if tag == "assign" && len(n) >= 3 {
			lhs, _ := n[1].([]any)
			rhs, _ := n[2].([]any)
			// Compute the base path to LHS within this assign node.
			lhsPath := append(append(mindscript.NodePath{}, path...), 1)
			var names []nameAt
			collectPat(lhs, lhsPath, &names)
			for _, na := range names {
				// Prefer precise SpanIndex range; fallback to token heuristic only if spans missing.
				rng, ok := rangeFromPath(doc, na.Path)
				if !ok {
					if s, e, ok2 := findDefIDRange(doc.tokens, na.Name); ok2 {
						rng = makeRange(doc.lines, s, e, doc.text)
					}
				}
				push(na.Name, rhs, rng)
			}
		}
		// Collect parameters as bindings: fun/oracle(x: T, ...) -> params of kind "param"
		if (tag == "fun" || tag == "oracle") && len(n) >= 3 {
			ps, _ := n[1].([]any) // params array
			if len(ps) > 0 && ps[0] == "array" {
				for i := 1; i < len(ps); i++ {
					pair, _ := ps[i].([]any) // ("pair"| "pair!", ("id", name), typeS)
					if len(pair) >= 3 && (pair[0] == "pair" || pair[0] == "pair!") {
						idNode, _ := pair[1].([]any)
						tNode, _ := pair[2].([]any)
						name := ""
						if len(idNode) >= 2 && idNode[0] == "id" {
							if s, ok := idNode[1].(string); ok {
								name = s
							}
						}
						if name != "" {
							// Path to id child (0-based NodePath indices):
							//   fun := ("fun", params, ret, body)
							//   params is child 0 in NodePath
							//   pair is (i-1) within params
							//   within ("pair", ("id", name), type), the ("id", ...) is child 0
							idPath := append(append(append(mindscript.NodePath{}, path...), 0), i-1)
							idPath = append(idPath, 0)
							rng, ok := rangeFromPath(doc, idPath)
							if !ok {
								// Fallback to token heuristic if spans missing (shouldn't happen)
								if s, e, ok := findDefIDRange(doc.tokens, name); ok {
									rng = makeRange(doc.lines, s, e, doc.text)
								}
							}
							out = append(out, bindingDef{
								Name:     name,
								Range:    rng,
								DocFull:  "",
								DocFirst: "",
								Kind:     "param",
								TypeNode: tNode,
							})
						}
					}
				}
			}
		}
		// Recurse
		for i := 1; i < len(n); i++ {
			if ch, ok := n[i].([]any); ok {
				walk(ch, append(path, i-1))
			}
		}
	}
	walk(doc.ast, mindscript.NodePath{})
	return out
}

// nearestBinding finds the binding with matching name whose definition appears
// at or before byte offset 'off', preferring the closest one. If none precede,
// it returns the earliest matching binding as a fallback.
func nearestBinding(doc *docState, name string, off int) (bindingDef, bool) {
	var best bindingDef
	bestOK := false
	bestStart := -1
	for _, b := range doc.binds {
		if b.Name != name {
			continue
		}
		// Definition start in bytes
		defOff := posToOffset(doc.lines, b.Range.Start, doc.text)
		if defOff <= off && defOff >= bestStart {
			best = b
			bestOK = true
			bestStart = defOff
		}
	}
	if bestOK {
		return best, true
	}
	// Fallback: earliest with that name
	earliest := -1
	for _, b := range doc.binds {
		if b.Name != name {
			continue
		}
		defOff := posToOffset(doc.lines, b.Range.Start, doc.text)
		if earliest == -1 || defOff < earliest {
			earliest = defOff
			best = b
			bestOK = true
		}
	}
	return best, bestOK
}

// collectTopLevelSymbols walks the AST (root-level only) and extracts symbols:
//   - let/assign of a simple decl: ("assign", ("decl", name), rhs)
//   - marks kind "fun" when rhs tag == "fun"; otherwise "let".
//
// Ranges are the byte range of the defining identifier token.
func collectTopLevelSymbols(doc *docState) []symbolDef {
	var out []symbolDef
	root := doc.ast
	if len(root) == 0 {
		return out
	}

	tag, _ := root[0].(string)
	if tag == "block" {
		for i := 1; i < len(root); i++ {
			if ch, ok := root[i].([]any); ok {
				ch = unwrapAnnotNode(ch)
				addTopLevelAssign(ch, doc, &out)
			}
		}
	} else {
		// Single-expression file that might still be an assignment.
		addTopLevelAssign(unwrapAnnotNode(root), doc, &out)
	}
	return out
}

// addTopLevelAssign adds a symbol for ("assign", ("decl", name), rhs).
// Kind is "fun" if rhs tag == "fun"; otherwise "let".
func addTopLevelAssign(node []any, doc *docState, out *[]symbolDef) {
	if len(node) < 3 {
		return
	}
	tag, _ := node[0].(string)
	if tag != "assign" {
		return
	}
	lhs, _ := node[1].([]any)
	if len(lhs) < 2 {
		return
	}
	lhsTag, _ := lhs[0].(string)
	var name string
	switch lhsTag {
	case "decl":
		name, _ = lhs[1].(string)
	case "id":
		// Allow plain identifier assignments:  f = fun(...),  beta = alpha
		name, _ = lhs[1].(string)
	default:
		// Ignore complex targets (destructuring etc.) for now.
		return
	}
	if name == "" {
		return
	}

	kind := "let"
	sig := ""
	docFirst := ""
	if rhs, ok := node[2].([]any); ok && len(rhs) > 0 {
		base, txt, _ := annotText(rhs) // doc text for first-line
		docFirst = firstLine(txt)
		if rtag, _ := base[0].(string); rtag == "fun" || rtag == "oracle" {
			kind = "fun"
			sig = formatFunSig(name, base)
		} else if rtag == "type" {
			kind = "type"
		}
	}

	// Find the defining identifier token's exact byte span.
	if start, end, ok := findDefIDRange(doc.tokens, name); ok {
		rng := makeRange(doc.lines, start, end, doc.text)
		*out = append(*out, symbolDef{
			Name:  name,
			Kind:  kind,
			Range: rng,
			Doc:   docFirst,
			Sig:   sig,
		})
	}
}

func findDefIDRange(toks []mindscript.Token, name string) (int, int, bool) {
	for i := 0; i < len(toks); i++ {
		tk := toks[i]
		if tk.Type != mindscript.ID {
			continue
		}
		if tokenName(tk) != name {
			continue
		}
		// def `x = ...`
		if i+1 < len(toks) && toks[i+1].Type == mindscript.ASSIGN {
			return tk.StartByte, tk.EndByte, true
		}
		// def `let x ...`
		if i-1 >= 0 && toks[i-1].Type == mindscript.LET {
			return tk.StartByte, tk.EndByte, true
		}
	}
	// Fallback: first occurrence (still better than nothing)
	for i := 0; i < len(toks); i++ {
		tk := toks[i]
		if tk.Type == mindscript.ID && tokenName(tk) == name {
			return tk.StartByte, tk.EndByte, true
		}
	}
	return 0, 0, false
}

func unwrapAnnotNode(n []any) []any {
	for {
		if len(n) >= 3 {
			if tag, _ := n[0].(string); tag == "annot" {
				if inner, _ := n[2].([]any); inner != nil {
					n = inner
					continue
				}
			}
		}
		return n
	}
}
=== END FILE: cmd/msg-lsp/core.go ===

=== BEGIN FILE: cmd/msg-lsp/features.go ===
// cmd/lsp/features.go
//
// ROLE: LSP feature implementations built on top of the caches/utilities from
//       core.go. Converts editor requests into language answers.
//
// What lives here
//   • Handlers for LSP methods:
//        - initialize: advertise capabilities and token legends.
//        - text sync (didOpen/didChange): update docState and trigger analyze.
//        - language features: hover, definition, references, completion,
//          document symbols, semantic tokens (full/range), signature help,
//          folding ranges.
//   • Heuristics that read docState (tokens, AST, spans, symbols) and format
//     LSP-shaped responses. Where useful, consults server.ip to surface
//     metadata about built-ins (e.g., function signatures) — without executing
//     user code. The optional listBindings() call that executed user code has
//     been removed to respect “don’t run user code in LSP.”
//
// What does NOT live here
//   • No transport framing or JSON-RPC loop (see main.go).
//   • No core text/position math or analysis pipeline (see core.go).
//   • No interpreter internals or VM usage; feature logic relies on lexer/parser
//     output and cached spans. Interpreter access is read-only for metadata.
//
// Why this separation
//   • Keeps feature code declarative and testable.
//   • Allows core analysis to evolve without touching user-visible features.
//
// Dependencies
//   • Consumes helpers/types from core.go and protocol.go.
//   • May read from s.ip.Global to describe built-ins; otherwise operates purely
//     on statically computed tokens/AST/symbols.

package main

import (
	"bytes"
	"encoding/json"
	"fmt"
	"sort"
	"strings"

	mindscript "github.com/DAIOS-AI/msg/internal/mindscript"
)

////////////////////////////////////////////////////////////////////////////////
// Initialize & text sync
////////////////////////////////////////////////////////////////////////////////

func (s *server) onInitialize(id json.RawMessage, _ json.RawMessage) {
	// Keep the token legend order in sync with semTypes in core.go
	legendTypes := []string{
		"keyword", "function", "type", "variable", "property",
		"string", "number", "comment", "bracket",
	}

	semProv := &struct {
		Legend struct {
			TokenTypes     []string `json:"tokenTypes"`
			TokenModifiers []string `json:"tokenModifiers"`
		} `json:"legend"`
		Full  bool `json:"full"`
		Range bool `json:"range"`
	}{Full: true, Range: true}
	semProv.Legend.TokenTypes = legendTypes
	semProv.Legend.TokenModifiers = []string{"b0", "b1", "b2", "b3", "b4", "b5"}

	result := InitializeResult{
		Capabilities: ServerCapabilities{
			TextDocumentSync: TextDocumentSyncOptions{
				OpenClose: true,
				Change:    2, // Incremental
			},
			HoverProvider:      true,
			DefinitionProvider: true,
			CompletionProvider: &struct {
				TriggerCharacters []string `json:"triggerCharacters"`
			}{TriggerCharacters: []string{".", ":", "[", "(", ","}},
			DocumentSymbolProvider:          true,
			ReferencesProvider:              true,
			WorkspaceSymbolProvider:         false,
			DocumentFormattingProvider:      false,
			DocumentRangeFormattingProvider: false,
			SignatureHelpProvider: &struct {
				TriggerCharacters   []string `json:"triggerCharacters"`
				RetriggerCharacters []string `json:"retriggerCharacters"`
			}{
				TriggerCharacters:   []string{"(", ","},
				RetriggerCharacters: []string{","},
			},
			SemanticTokensProvider: semProv,
			FoldingRangeProvider:   true,
		},
		ServerInfo: map[string]string{
			"name":    "mindscript-lsp",
			"version": "0.4",
		},
	}
	s.sendResponse(id, result, nil)
}

func (s *server) onDidOpen(raw json.RawMessage) {
	var params struct {
		TextDocument TextDocumentItem `json:"textDocument"`
	}
	_ = json.Unmarshal(raw, &params)
	s.mu.Lock()
	doc := &docState{
		uri:   params.TextDocument.URI,
		text:  params.TextDocument.Text,
		lines: lineOffsets(params.TextDocument.Text),
	}
	s.docs[doc.uri] = doc
	s.mu.Unlock()
	s.analyze(doc)
}

func (s *server) onDidChange(raw json.RawMessage) {
	var params struct {
		TextDocument struct {
			URI string `json:"uri"`
		} `json:"textDocument"`
		ContentChanges []TextDocumentContentChangeEvent `json:"contentChanges"`
	}
	_ = json.Unmarshal(raw, &params)

	s.mu.Lock()
	doc := s.docs[params.TextDocument.URI]
	s.mu.Unlock()
	if doc == nil || len(params.ContentChanges) == 0 {
		return
	}

	// If any change is a full replace, follow LSP convention and treat it as the only change.
	fullIdx := -1
	for i, ch := range params.ContentChanges {
		if ch.Range == nil {
			fullIdx = i
			break
		}
	}
	if fullIdx >= 0 {
		doc.text = params.ContentChanges[fullIdx].Text
		doc.lines = lineOffsets(doc.text)
		s.analyze(doc)
		return
	}

	// Apply incremental edits in order; recompute line offsets after each to keep positions valid.
	for _, ch := range params.ContentChanges {
		start := posToOffset(doc.lines, ch.Range.Start, doc.text)
		end := posToOffset(doc.lines, ch.Range.End, doc.text)
		var b bytes.Buffer
		b.WriteString(doc.text[:start])
		b.WriteString(ch.Text)
		if end < len(doc.text) {
			b.WriteString(doc.text[end:])
		}
		doc.text = b.String()
		doc.lines = lineOffsets(doc.text)
	}
	s.analyze(doc)
}

////////////////////////////////////////////////////////////////////////////////
// Hover
////////////////////////////////////////////////////////////////////////////////

func (s *server) onHover(id json.RawMessage, paramsRaw json.RawMessage) {
	var params struct {
		TextDocument TextDocumentIdentifier `json:"textDocument"`
		Position     Position               `json:"position"`
	}
	_ = json.Unmarshal(paramsRaw, &params)

	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, nil, nil)
		return
	}

	name, rng := wordAt(doc, params.Position)
	if name == "" {
		s.sendResponse(id, nil, nil)
		return
	}

	off := posToOffset(doc.lines, params.Position, doc.text)
	_, tk, _, _, tokOK := tokenAtOffset(doc, off)

	// Keywords / boolean literals → simple hover
	if tokOK {
		if isKeywordButNotType(tk.Type) || tk.Type == mindscript.BOOLEAN {
			word := tk.Lexeme
			if tk.Type == mindscript.BOOLEAN {
				if b, ok := tk.Literal.(bool); ok && b {
					word = "true"
				} else {
					word = "false"
				}
			}
			content := fmt.Sprintf("**keyword** `%s`", word)
			s.sendResponse(id, Hover{Contents: MarkupContent{Kind: "markdown", Value: content}, Range: &rng}, nil)
			return
		}
	}

	// Prefer the nearest binding (uniform; includes annotations for all kinds + type/sig)
	if b, ok := nearestBinding(doc, name, off); ok {
		var header string
		switch b.Kind {
		case "fun", "oracle":
			sig := b.Sig
			if sig == "" {
				// fallback to minimal presentation
				sig = name + "(...) -> Any"
			}
			header = fmt.Sprintf("**fun** `%s`", sig)
		case "type":
			header = fmt.Sprintf("**type** `%s`", name)
		case "param":
			ty := formatTypeNode(b.TypeNode)
			header = fmt.Sprintf("**param** `%s: %s`", name, ty)
		default:
			ty := formatTypeNode(b.TypeNode)
			if ty != "" && ty != "Any" {
				header = fmt.Sprintf("**variable** `%s: %s`", name, ty)
			} else {
				header = fmt.Sprintf("**variable** `%s`", name)
			}
		}
		content := header
		if txt := strings.TrimSpace(b.DocFull); txt != "" {
			content += "\n\n" + txt
		}
		s.sendResponse(id, Hover{Contents: MarkupContent{Kind: "markdown", Value: content}, Range: &rng}, nil)
		return
	}

	// Builtin types by ID (NOT by TYPE keyword)
	if tokOK && tk.Type == mindscript.ID {
		if docTxt, ok := builtinTypeDocs[name]; ok {
			content := fmt.Sprintf("**type** `%s`\n\n%s", name, docTxt)
			s.sendResponse(id, Hover{Contents: MarkupContent{Kind: "markdown", Value: content}, Range: &rng}, nil)
			return
		}
	}

	// Globals from interpreter (functions/types) — metadata only, no user code execution
	if v, err := s.ip.Global.Get(name); err == nil {
		switch v.Tag {
		case mindscript.VTFun:
			if meta, ok := s.ip.FunMeta(v); ok {
				ps := meta.ParamSpecs()
				parts := make([]string, 0, len(ps))
				for _, p := range ps {
					parts = append(parts, fmt.Sprintf("%s: %s", p.Name, mindscript.FormatType(p.Type)))
				}
				ret := mindscript.FormatType(meta.ReturnType())
				content := fmt.Sprintf("**fun** `%s(%s) -> %s`", name, strings.Join(parts, ", "), ret)
				if doc := strings.TrimSpace(meta.Doc()); doc != "" {
					content += "\n\n" + doc
				}
				s.sendResponse(id, Hover{Contents: MarkupContent{Kind: "markdown", Value: content}, Range: &rng}, nil)
				return
			}
		case mindscript.VTType:
			content := "**type** `" + name + "`"
			s.sendResponse(id, Hover{Contents: MarkupContent{Kind: "markdown", Value: content}, Range: &rng}, nil)
			return
		}
	}

	// Fallback classification for IDs (kept for completeness)
	if tokOK && tk.Type == mindscript.ID {
		kind := "identifier"
		idx := -1
		if i, _, _, _, ok := tokenAtOffset(doc, off); ok {
			idx = i
		}
		if idx == -1 {
			for i := range doc.tokens {
				if doc.tokens[i] == tk {
					idx = i
					break
				}
			}
		}

		if idx >= 1 && doc.tokens[idx-1].Type == mindscript.PERIOD {
			kind = "property"
		} else if sy, ok := findSymbol(doc, name); ok && sy.Kind != "" {
			kind = sy.Kind
		} else if idx+1 < len(doc.tokens) && doc.tokens[idx+1].Type == mindscript.CLROUND {
			kind = "fun"
		} else if v, err := s.ip.Global.Get(name); err == nil && v.Tag == mindscript.VTType {
			kind = "type"
		}
		content := fmt.Sprintf("**%s** `%s`", kind, name)
		s.sendResponse(id, Hover{Contents: MarkupContent{Kind: "markdown", Value: content}, Range: &rng}, nil)
		return
	}

	s.sendResponse(id, nil, nil)
}

////////////////////////////////////////////////////////////////////////////////
// Definition
////////////////////////////////////////////////////////////////////////////////

func (s *server) onDefinition(id json.RawMessage, paramsRaw json.RawMessage) {
	var params struct {
		TextDocument TextDocumentIdentifier `json:"textDocument"`
		Position     Position               `json:"position"`
	}
	_ = json.Unmarshal(paramsRaw, &params)

	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, nil, nil)
		return
	}
	name, _ := wordAt(doc, params.Position)
	if name == "" {
		s.sendResponse(id, nil, nil)
		return
	}
	off := posToOffset(doc.lines, params.Position, doc.text)
	if b, ok := nearestBinding(doc, name, off); ok {
		s.sendResponse(id, Location{URI: doc.uri, Range: b.Range}, nil)
		return
	}
	// Fallback: old top-level heuristic
	for _, sym := range doc.symbols {
		if sym.Name == name {
			s.sendResponse(id, Location{URI: doc.uri, Range: sym.Range}, nil)
			return
		}
	}
	s.sendResponse(id, nil, nil)
}

////////////////////////////////////////////////////////////////////////////////
// Completion
////////////////////////////////////////////////////////////////////////////////

func (s *server) onCompletion(id json.RawMessage, paramsRaw json.RawMessage) {
	var params struct {
		TextDocument TextDocumentIdentifier `json:"textDocument"`
		Position     Position               `json:"position"`
	}
	_ = json.Unmarshal(paramsRaw, &params)

	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, []CompletionItem{}, nil)
		return
	}

	// If cursor is inside a STRING or any ANNOTATION span, suppress completions.
	off := posToOffset(doc.lines, params.Position, doc.text)
	if _, tk, _, _, ok := tokenAtOffset(doc, off); ok {
		if tk.Type == mindscript.STRING {
			s.sendResponse(id, []CompletionItem{}, nil)
			return
		}
	}
	for _, sp := range commentSpans(doc) {
		if off >= sp[0] && off < sp[1] {
			s.sendResponse(id, []CompletionItem{}, nil)
			return
		}
	}

	seen := map[string]bool{}
	items := make([]CompletionItem, 0, 128)

	// Uniform: suggest from all bindings we know in this file (with kind/signature or type)
	for _, b := range doc.binds {
		if seen[b.Name] {
			continue
		}
		seen[b.Name] = true
		kind := 6 // Variable
		switch b.Kind {
		case "fun", "oracle":
			kind = 3 // Function
		case "type":
			kind = 5 // Class-ish
		case "param":
			kind = 6 // Variable (parameter)
		}
		detail := b.Kind
		if b.Kind == "fun" || b.Kind == "oracle" {
			if b.Sig != "" {
				detail = b.Sig
			}
		} else {
			ty := formatTypeNode(b.TypeNode)
			if ty != "" && ty != "Any" {
				if detail != "" {
					detail = detail + " · " + ty
				} else {
					detail = ty
				}
			}
		}
		items = append(items, CompletionItem{
			Label:  b.Name,
			Kind:   kind,
			Detail: detail,
		})
	}

	// Language keywords (MindScript-specific spellings)
	keywords := []string{
		"and", "or", "not",
		"let", "do", "end", "return", "break", "continue",
		"if", "then", "elif", "else",
		"fun", "oracle",
		"for", "in", "from", "while",
		"type", "enum",
		"null", "true", "false",
	}
	for _, kw := range keywords {
		if !seen[kw] {
			seen[kw] = true
			items = append(items, CompletionItem{Label: kw, Kind: 14}) // Keyword
		}
	}

	sort.Slice(items, func(i, j int) bool { return items[i].Label < items[j].Label })
	s.sendResponse(id, items, nil)
}

////////////////////////////////////////////////////////////////////////////////
// Document symbols
////////////////////////////////////////////////////////////////////////////////

func (s *server) onDocumentSymbols(id json.RawMessage, paramsRaw json.RawMessage) {
	var params struct {
		TextDocument TextDocumentIdentifier `json:"textDocument"`
	}
	_ = json.Unmarshal(paramsRaw, &params)

	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, []DocumentSymbol{}, nil)
		return
	}

	out := make([]DocumentSymbol, 0, len(doc.symbols))
	for _, sym := range doc.symbols {
		kind := 13 // Variable
		switch sym.Kind {
		case "fun":
			kind = 12 // Function
		case "type":
			kind = 5 // Class-ish
		}
		detail := sym.Kind
		if sym.Kind == "fun" && sym.Sig != "" {
			detail = sym.Sig
		}
		out = append(out, DocumentSymbol{
			Name:           sym.Name,
			Detail:         detail,
			Kind:           kind,
			Range:          sym.Range,
			SelectionRange: sym.Range,
		})
	}
	s.sendResponse(id, out, nil)
}

////////////////////////////////////////////////////////////////////////////////
// References
////////////////////////////////////////////////////////////////////////////////

func (s *server) onReferences(id json.RawMessage, paramsRaw json.RawMessage) {
	var params struct {
		TextDocument TextDocumentIdentifier `json:"textDocument"`
		Position     Position               `json:"position"`
		Context      struct {
			IncludeDeclaration bool `json:"includeDeclaration"`
		} `json:"context"`
	}
	_ = json.Unmarshal(paramsRaw, &params)

	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, []Location{}, nil)
		return
	}

	name, _ := wordAt(doc, params.Position)
	if name == "" {
		s.sendResponse(id, []Location{}, nil)
		return
	}

	// Resolve the specific binding at the query position.
	qOff := posToOffset(doc.lines, params.Position, doc.text)
	bOrigin, ok := nearestBinding(doc, name, qOff)
	if !ok {
		// fallback: all occurrences of the bare identifier (minus properties)
		locs := []Location{}
		for i, t := range doc.tokens {
			if t.Type != mindscript.ID || tokenName(t) != name {
				continue
			}
			if i-1 >= 0 && doc.tokens[i-1].Type == mindscript.PERIOD {
				continue
			}
			start, end := tokenSpan(doc, t)
			locs = append(locs, Location{
				URI:   doc.uri,
				Range: makeRange(doc.lines, start, end, doc.text),
			})
		}
		s.sendResponse(id, locs, nil)
		return
	}

	// Shadowing-aware: include only occurrences that resolve to the same nearest binding.
	locs := []Location{}
	for i, t := range doc.tokens {
		if t.Type != mindscript.ID || tokenName(t) != name {
			continue
		}
		// Exclude property names: immediately preceded by '.'
		if i-1 >= 0 && doc.tokens[i-1].Type == mindscript.PERIOD {
			continue
		}
		sOff, eOff := tokenSpan(doc, t)
		// Use the start of the token as its "position"
		if bTok, ok := nearestBinding(doc, name, sOff); ok {
			if bTok.Range == bOrigin.Range {
				locs = append(locs, Location{
					URI:   doc.uri,
					Range: makeRange(doc.lines, sOff, eOff, doc.text),
				})
			}
		}
	}
	s.sendResponse(id, locs, nil)
}

////////////////////////////////////////////////////////////////////////////////
// Semantic tokens (full & range)
////////////////////////////////////////////////////////////////////////////////

func (s *server) onSemanticTokensFull(id json.RawMessage, paramsRaw json.RawMessage) {
	var params SemanticTokensParams
	_ = json.Unmarshal(paramsRaw, &params)
	doc := s.snapshotDoc(params.TextDocument.URI)
	data := s.semanticTokensData(doc, -1, -1) // full
	s.sendResponse(id, SemanticTokens{Data: data}, nil)
}

func (s *server) onSemanticTokensRange(id json.RawMessage, paramsRaw json.RawMessage) {
	var params SemanticTokensRangeParams
	_ = json.Unmarshal(paramsRaw, &params)
	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, SemanticTokens{Data: nil}, nil)
		return
	}
	start := posToOffset(doc.lines, params.Range.Start, doc.text)
	end := posToOffset(doc.lines, params.Range.End, doc.text)
	data := s.semanticTokensData(doc, start, end)
	s.sendResponse(id, SemanticTokens{Data: data}, nil)
}

type semEntry struct {
	line, ch, lenU16, typ int
	mods                  uint32
}

// Keyword “brackets” for semantic coloring:
func isKeywordOpen(t mindscript.Token) bool {
	return t.Type == mindscript.DO || t.Type == mindscript.THEN
}
func isKeywordClose(t mindscript.Token) bool {
	return t.Type == mindscript.END || t.Type == mindscript.ELIF
}
func isKeywordCloseReopen(t mindscript.Token) bool {
	return t.Type == mindscript.ELSE
}

// semanticTokensData builds LSP-encoded semantic token data.
// If [selStart, selEnd) are >=0, only tokens overlapping that range are emitted.
func (s *server) semanticTokensData(doc *docState, selStart, selEnd int) []uint32 {
	if doc == nil || len(doc.tokens) == 0 {
		return nil
	}

	cspans := commentSpans(doc)

	isInComment := func(sOff, eOff int) bool {
		se := [2]int{sOff, eOff}
		for _, c := range cspans {
			if overlaps(se, c) {
				return true
			}
		}
		return false
	}

	entries := []semEntry{}

	// Emit code tokens, skipping anything inside comment spans.
	// Track brace depth to classify map-literal keys (`id`/`"str"`) as properties.
	braceDepth := 0

	for i := 0; i < len(doc.tokens); i++ {
		tk := doc.tokens[i]
		if tk.Type == mindscript.ANNOTATION {
			// the whole annotation region already colored as comment
			continue
		}

		sOff, eOff := tokenSpan(doc, tk)
		if eOff <= sOff {
			// still keep structural depth in sync
			if tk.Type == mindscript.LCURLY {
				braceDepth++
			} else if tk.Type == mindscript.RCURLY && braceDepth > 0 {
				braceDepth--
			}
			continue
		}

		if selStart >= 0 && selEnd >= 0 && !(eOff > selStart && sOff < selEnd) {
			// maintain depth even when skipping by range
			if tk.Type == mindscript.LCURLY {
				braceDepth++
			} else if tk.Type == mindscript.RCURLY && braceDepth > 0 {
				braceDepth--
			}
			continue
		}

		if isInComment(sOff, eOff) {
			// maintain depth across comments
			if tk.Type == mindscript.LCURLY {
				braceDepth++
			} else if tk.Type == mindscript.RCURLY && braceDepth > 0 {
				braceDepth--
			}
			continue
		}

		typIdx := -1
		switch {
		case isKeywordButNotType(tk.Type) || tk.Type == mindscript.BOOLEAN:
			// Let the bracket pass own do/then/elif/else/end so we don't duplicate tokens.
			if isKeywordOpen(tk) || isKeywordClose(tk) || isKeywordCloseReopen(tk) {
				// maintain depth for braces only (not relevant here), then skip emission
				if tk.Type == mindscript.LCURLY {
					braceDepth++
				} else if tk.Type == mindscript.RCURLY && braceDepth > 0 {
					braceDepth--
				}
				continue
			}
			typIdx = semTypes["keyword"]

		case tk.Type == mindscript.STRING:
			// Property after '.' OR map key before ':'
			if i-1 >= 0 && doc.tokens[i-1].Type == mindscript.PERIOD {
				typIdx = semTypes["property"]
			} else if braceDepth > 0 && i+1 < len(doc.tokens) && doc.tokens[i+1].Type == mindscript.COLON {
				typIdx = semTypes["property"]
			} else {
				typIdx = semTypes["string"]
			}

		case tk.Type == mindscript.INTEGER || tk.Type == mindscript.NUMBER:
			typIdx = semTypes["number"]

		case tk.Type == mindscript.ID:
			name := tokenName(tk)
			idx := i // avoid O(n) indexOfToken
			if idx >= 1 && doc.tokens[idx-1].Type == mindscript.PERIOD {
				typIdx = semTypes["property"]
			} else if braceDepth > 0 && i+1 < len(doc.tokens) && doc.tokens[i+1].Type == mindscript.COLON {
				// `{ key: ... }`
				typIdx = semTypes["property"]
			} else {
				kind := ""
				if sy, ok := findSymbol(doc, name); ok {
					kind = sy.Kind
				}
				if kind == "fun" || (idx+1 < len(doc.tokens) && doc.tokens[idx+1].Type == mindscript.CLROUND) {
					typIdx = semTypes["function"]
				} else if kind == "type" {
					typIdx = semTypes["type"]
				} else if v, err := s.ip.Global.Get(name); err == nil && v.Tag == mindscript.VTType {
					typIdx = semTypes["type"]
				} else {
					typIdx = semTypes["variable"]
				}
			}

		default:
			// keep depth updated, even if we don't emit anything
			if tk.Type == mindscript.LCURLY {
				braceDepth++
			} else if tk.Type == mindscript.RCURLY && braceDepth > 0 {
				braceDepth--
			}
			continue
		}

		// LSP requires single-line tokens. Split on newlines.
		segStart := sOff
		for cur := sOff; cur < eOff; cur++ {
			if doc.text[cur] == '\r' {
				continue
			}
			if doc.text[cur] == '\n' {
				if segStart < cur {
					st := offsetToPos(doc.lines, segStart, doc.text)
					entries = append(entries, semEntry{
						line:   st.Line,
						ch:     st.Character,
						lenU16: u16Len(doc.text[segStart:cur]),
						typ:    typIdx,
						mods:   0,
					})
				}
				segStart = cur + 1
			}
		}
		if segStart < eOff {
			st := offsetToPos(doc.lines, segStart, doc.text)
			entries = append(entries, semEntry{
				line:   st.Line,
				ch:     st.Character,
				lenU16: u16Len(doc.text[segStart:eOff]),
				typ:    typIdx,
				mods:   0,
			})
		}

		// update structural depth after processing a token
		if tk.Type == mindscript.LCURLY {
			braceDepth++
		} else if tk.Type == mindscript.RCURLY && braceDepth > 0 {
			braceDepth--
		}
	}

	// ---------- Keyword bracket pass (adds entries; no duplication with main pass) ----------
	const maxLevels = 6
	level := 0
	push := func() {
		if level < maxLevels-1 {
			level++
		}
	}
	pop := func() {
		if level > 0 {
			level--
		}
	}

	for i := 0; i < len(doc.tokens); i++ {
		tk := doc.tokens[i]

		// Compute token span; obey range filter & comment masking
		sOff, eOff := tokenSpan(doc, tk)
		if eOff <= sOff {
			continue
		}
		if selStart >= 0 && selEnd >= 0 && !(eOff > selStart && sOff < selEnd) {
			continue
		}
		if isInComment(sOff, eOff) {
			continue
		}
		// Strings are opaque; keywords inside strings are not structure.
		if tk.Type == mindscript.STRING {
			continue
		}
		// Only bracket-like keywords
		if !(isKeywordOpen(tk) || isKeywordClose(tk) || isKeywordCloseReopen(tk)) {
			continue
		}

		typIdx := semTypes["bracket"]
		// Use the *closing* level for close/close-reopen so matching pairs share the same color.
		// Example: after 'then' we push (depth=1). On 'end', we want the same b* as 'then' → level-1.
		lvl := level
		if isKeywordClose(tk) || isKeywordCloseReopen(tk) {
			if lvl > 0 {
				lvl--
			}
		}
		modBit := uint32(1 << lvl) // maps to b0..b5 in package.json

		emit := func(segStart, segEnd int) {
			st := offsetToPos(doc.lines, segStart, doc.text)
			entries = append(entries, semEntry{
				line:   st.Line,
				ch:     st.Character,
				lenU16: u16Len(doc.text[segStart:segEnd]),
				typ:    typIdx,
				mods:   modBit,
			})
		}

		// Split by line exactly like the main pass
		segStart := sOff
		for cur := sOff; cur < eOff; cur++ {
			if doc.text[cur] == '\r' {
				continue
			}
			if doc.text[cur] == '\n' {
				if segStart < cur {
					emit(segStart, cur)
				}
				segStart = cur + 1
			}
		}
		if segStart < eOff {
			emit(segStart, eOff)
		}

		// Update nesting after emission
		switch {
		case isKeywordOpen(tk):
			push()
		case isKeywordCloseReopen(tk):
			pop()
			push()
		case isKeywordClose(tk):
			pop()
		}
	}

	// Sort then delta-encode
	sort.Slice(entries, func(i, j int) bool {
		if entries[i].line != entries[j].line {
			return entries[i].line < entries[j].line
		}
		return entries[i].ch < entries[j].ch
	})
	data := make([]uint32, 0, len(entries)*5)
	prevLine, prevCh := 0, 0
	first := true
	for _, e := range entries {
		dl, dc := e.line, e.ch
		if !first {
			dl -= prevLine
			if dl == 0 {
				dc -= prevCh
			}
		}
		first = false
		prevLine, prevCh = e.line, e.ch
		data = append(data, uint32(dl), uint32(dc), uint32(e.lenU16), uint32(e.typ), e.mods)
	}
	return data
}

////////////////////////////////////////////////////////////////////////////////
// Signature help
////////////////////////////////////////////////////////////////////////////////

func (s *server) onSignatureHelp(id json.RawMessage, paramsRaw json.RawMessage) {
	var params SignatureHelpParams
	_ = json.Unmarshal(paramsRaw, &params)

	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, SignatureHelp{}, nil)
		return
	}

	off := posToOffset(doc.lines, params.Position, doc.text)
	tIdx, _, _, _, ok := tokenAtOffset(doc, off)
	if !ok && len(doc.tokens) > 0 {
		tIdx = len(doc.tokens) - 1
	}

	// Walk left to find the matching '(' (CLROUND) with proper nesting.
	depth := 0
	openIdx := -1
	for i := tIdx; i >= 0; i-- {
		switch doc.tokens[i].Type {
		case mindscript.RROUND:
			depth++
		case mindscript.CLROUND, mindscript.LROUND:
			if depth == 0 {
				openIdx = i
				goto found
			}
			depth--
		}
	}
found:
	if openIdx < 0 || doc.tokens[openIdx].Type != mindscript.CLROUND {
		s.sendResponse(id, SignatureHelp{}, nil)
		return
	}

	// Try to get the callee name (simple heuristic: previous ID)
	name := ""
	if openIdx-1 >= 0 && doc.tokens[openIdx-1].Type == mindscript.ID {
		name = tokenName(doc.tokens[openIdx-1])
	}

	// Count commas at top-level between '(' and cursor to find active parameter.
	paramIdx := 0
	depth = 0
	for i := openIdx + 1; i < len(doc.tokens); i++ {
		tk := doc.tokens[i]
		sOff, eOff := tokenSpan(doc, tk)
		if off < sOff {
			break
		}
		switch tk.Type {
		case mindscript.CLROUND, mindscript.LROUND:
			depth++
		case mindscript.RROUND:
			if depth == 0 {
				i = len(doc.tokens) // break two loops
				break
			}
			depth--
		case mindscript.COMMA:
			if depth == 0 && off >= sOff && off >= eOff {
				paramIdx++
			}
		}
	}

	// Build signature(s)
	resp := SignatureHelp{
		Signatures:      []SignatureInformation{},
		ActiveSignature: 0,
		ActiveParameter: paramIdx,
	}

	// Prefer a local binding signature if available
	if name != "" {
		for _, b := range doc.binds {
			if b.Name == name && (b.Kind == "fun" || b.Kind == "oracle") && b.Sig != "" {
				resp.Signatures = append(resp.Signatures, SignatureInformation{Label: b.Sig})
				s.sendResponse(id, resp, nil)
				return
			}
		}
		// Fall back to top-level symbol sig (if present)
		for _, sym := range doc.symbols {
			if sym.Name == name && sym.Kind == "fun" {
				label := sym.Sig
				if label == "" {
					label = name + "(...) -> Any"
				}
				resp.Signatures = append(resp.Signatures, SignatureInformation{Label: label})
				s.sendResponse(id, resp, nil)
				return
			}
		}
		// Try global meta (metadata only; no user code execution)
		if v, err := s.ip.Global.Get(name); err == nil && v.Tag == mindscript.VTFun {
			if meta, ok := s.ip.FunMeta(v); ok {
				ps := meta.ParamSpecs()
				parts := make([]string, 0, len(ps))
				paramsInfo := make([]ParameterInformation, 0, len(ps))
				for _, p := range ps {
					seg := fmt.Sprintf("%s: %s", p.Name, mindscript.FormatType(p.Type))
					parts = append(parts, seg)
					paramsInfo = append(paramsInfo, ParameterInformation{Label: seg})
				}
				label := fmt.Sprintf("%s(%s) -> %s", name, strings.Join(parts, ", "), mindscript.FormatType(meta.ReturnType()))
				docm := strings.TrimSpace(meta.Doc())
				var docPtr *MarkupContent
				if docm != "" {
					docPtr = &MarkupContent{Kind: "markdown", Value: docm}
				}
				resp.Signatures = append(resp.Signatures, SignatureInformation{
					Label:         label,
					Documentation: docPtr,
					Parameters:    paramsInfo,
				})
				s.sendResponse(id, resp, nil)
				return
			}
		}
	}

	// Unknown function — provide a minimal shell
	if name != "" {
		resp.Signatures = append(resp.Signatures, SignatureInformation{Label: name + "(…)"})
	}
	s.sendResponse(id, resp, nil)
}

////////////////////////////////////////////////////////////////////////////////
// Folding ranges
////////////////////////////////////////////////////////////////////////////////

func (s *server) onFoldingRange(id json.RawMessage, paramsRaw json.RawMessage) {
	var params struct {
		TextDocument TextDocumentIdentifier `json:"textDocument"`
	}
	_ = json.Unmarshal(paramsRaw, &params)

	doc := s.snapshotDoc(params.TextDocument.URI)
	if doc == nil {
		s.sendResponse(id, []FoldingRange{}, nil)
		return
	}

	var out []FoldingRange

	// Comment/annotation blocks
	for _, sp := range commentSpans(doc) {
		startLine := offsetToPos(doc.lines, sp[0], doc.text).Line
		endLine := offsetToPos(doc.lines, sp[1], doc.text).Line
		if endLine > startLine {
			kind := "comment"
			out = append(out, FoldingRange{StartLine: startLine, EndLine: endLine, Kind: &kind})
		}
	}

	// AST-based folding using spans (starts at headers, ends at closing)
	if doc.spans != nil && doc.ast != nil && len(doc.ast) > 0 {
		foldable := map[string]bool{
			"fun": true, "oracle": true, "if": true, "while": true, "for": true,
			// Optional: fold big literals too
			"array": true, "map": true,
		}
		var walk func(node []any, path mindscript.NodePath)
		walk = func(node []any, path mindscript.NodePath) {
			if len(node) == 0 {
				return
			}
			tag, _ := node[0].(string)
			if foldable[tag] {
				if sp, ok := doc.spans.Get(path); ok {
					startL := offsetToPos(doc.lines, sp.StartByte, doc.text).Line
					endL := offsetToPos(doc.lines, sp.EndByte, doc.text).Line
					if endL > startL {
						out = append(out, FoldingRange{StartLine: startL, EndLine: endL})
					}
				}
			}
			for i := 1; i < len(node); i++ {
				if ch, ok := node[i].([]any); ok {
					walk(ch, append(path, i-1))
				}
			}
		}
		walk(doc.ast, mindscript.NodePath{})
	}

	s.sendResponse(id, out, nil)
}
=== END FILE: cmd/msg-lsp/features.go ===

=== BEGIN FILE: cmd/msg-lsp/main.go ===
// cmd/lsp/main.go
//
// ROLE: Executable entrypoint and JSON-RPC dispatch loop.
//
// What lives here
//   • Process startup and server construction.
//   • Framed JSON-RPC read loop from stdin and write to stdout.
//   • Method routing: decode → switch on req.Method → delegate to server
//     handlers in features.go / core.go.
//   • Minimal lifecycle handling (initialize/shutdown/exit).
//
// What does NOT live here
//   • No language features, no text analysis, no diagnostics computation,
//     no document state. Keep this file small so it’s easy to test/replace
//     the transport without touching feature logic.
//
// Why this separation
//   • Clear boundary between transport concerns and language intelligence.
//   • Enables reuse of the server with different frontends/transports.

package main

import (
	"bufio"
	"encoding/json"
	"fmt"
	"io"
	"os"
)

func main() {
	s := newServer()
	in := bufio.NewReader(os.Stdin)

	for {
		msgBytes, err := readMsg(in)
		if err != nil {
			if err != io.EOF {
				// best-effort log to stderr
				fmt.Fprintln(os.Stderr, "read error:", err)
			}
			return
		}

		var req Request
		if err := json.Unmarshal(msgBytes, &req); err != nil {
			// Malformed JSON—ignore silently to be robust
			continue
		}

		switch req.Method {
		// LSP lifecycle
		case "initialize":
			s.onInitialize(req.ID, req.Params)
		case "initialized":
			// no-op
		case "shutdown":
			s.sendResponse(req.ID, nil, nil)
		case "exit":
			return

		// Text sync
		case "textDocument/didOpen":
			s.onDidOpen(req.Params)
		case "textDocument/didChange":
			s.onDidChange(req.Params)

		// Language features
		case "textDocument/hover":
			s.onHover(req.ID, req.Params)
		case "textDocument/definition":
			s.onDefinition(req.ID, req.Params)
		case "textDocument/completion":
			s.onCompletion(req.ID, req.Params)
		case "textDocument/documentSymbol":
			s.onDocumentSymbols(req.ID, req.Params)
		case "textDocument/references":
			s.onReferences(req.ID, req.Params)
		case "textDocument/signatureHelp":
			s.onSignatureHelp(req.ID, req.Params)
		case "textDocument/foldingRange":
			s.onFoldingRange(req.ID, req.Params)

		// Semantic tokens
		case "textDocument/semanticTokens/full":
			s.onSemanticTokensFull(req.ID, req.Params)
		case "textDocument/semanticTokens/range":
			s.onSemanticTokensRange(req.ID, req.Params)

		default:
			// For requests (have an id), reply with MethodNotFound; notifications are ignored.
			if len(req.ID) > 0 {
				s.sendResponse(req.ID, nil, &ResponseError{Code: -32601, Message: "method not found"})
			}
		}
	}
}
=== END FILE: cmd/msg-lsp/main.go ===

=== BEGIN FILE: cmd/msg-lsp/protocol.go ===
// cmd/lsp/protocol.go
//
// ROLE: Pure wire schema for JSON-RPC 2.0 and the Language Server Protocol (LSP).
//
// What lives here
//   • Go structs that mirror the on-the-wire request/response envelopes and
//     LSP payload types (positions, ranges, diagnostics, hovers, completion,
//     semantic tokens, folding, signature help, etc.).
//
// What does NOT live here
//   • No business logic, no transport framing, no feature handlers, no
//     server state. This file must remain DTOs only so the rest of the
//     codebase can import it without pulling any behavior.
//
// Why this separation
//   • Keeps (de)serialization types stable and dependency-free.
//   • Makes it easy to audit protocol changes and keep handlers decoupled.
//
// Dependencies: none (stdlib only).

package main

import "encoding/json"

////////////////////////////////////////////////////////////////////////////////
// LSP protocol types (wire structs)
////////////////////////////////////////////////////////////////////////////////

// ----- JSON-RPC envelope -----

type Request struct {
	JSONRPC string          `json:"jsonrpc"`
	ID      json.RawMessage `json:"id,omitempty"`
	Method  string          `json:"method"`
	Params  json.RawMessage `json:"params,omitempty"`
}

type Response struct {
	JSONRPC string          `json:"jsonrpc"`
	ID      json.RawMessage `json:"id,omitempty"`
	Result  any             `json:"result,omitempty"`
	Error   *ResponseError  `json:"error,omitempty"`
}

type ResponseError struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
}

// ----- LSP core value types -----

type Position struct {
	Line      int `json:"line"`
	Character int `json:"character"` // UTF-16 code units
}

type Range struct {
	Start Position `json:"start"`
	End   Position `json:"end"`
}

type Location struct {
	URI   string `json:"uri"`
	Range Range  `json:"range"`
}

// ----- Text document -----

type TextDocumentIdentifier struct {
	URI string `json:"uri"`
}

type TextDocumentItem struct {
	URI        string `json:"uri"`
	LanguageID string `json:"languageId"`
	Version    int    `json:"version"`
	Text       string `json:"text"`
}

type TextDocumentContentChangeEvent struct {
	Range       *Range `json:"range,omitempty"`
	RangeLength int    `json:"rangeLength,omitempty"`
	Text        string `json:"text"`
}

// ----- Initialize / capabilities -----

type InitializeParams struct {
	Capabilities any    `json:"capabilities"`
	RootURI      string `json:"rootUri,omitempty"`
}

type TextDocumentSyncOptions struct {
	OpenClose bool `json:"openClose"`
	// 1 = Full, 2 = Incremental
	Change            int  `json:"change"`
	WillSave          bool `json:"willSave"`
	WillSaveWaitUntil bool `json:"willSaveWaitUntil"`
	Save              *struct {
		IncludeText bool `json:"includeText"`
	} `json:"save,omitempty"`
}

type ServerCapabilities struct {
	TextDocumentSync   TextDocumentSyncOptions `json:"textDocumentSync"`
	HoverProvider      bool                    `json:"hoverProvider"`
	DefinitionProvider bool                    `json:"definitionProvider"`
	CompletionProvider *struct {
		TriggerCharacters []string `json:"triggerCharacters"`
	} `json:"completionProvider,omitempty"`
	DocumentSymbolProvider          bool `json:"documentSymbolProvider"`
	ReferencesProvider              bool `json:"referencesProvider"`
	WorkspaceSymbolProvider         bool `json:"workspaceSymbolProvider"`
	DocumentFormattingProvider      bool `json:"documentFormattingProvider"`
	DocumentRangeFormattingProvider bool `json:"documentRangeFormattingProvider"`
	SignatureHelpProvider           *struct {
		TriggerCharacters   []string `json:"triggerCharacters"`
		RetriggerCharacters []string `json:"retriggerCharacters"`
	} `json:"signatureHelpProvider,omitempty"`
	SemanticTokensProvider *struct {
		Legend struct {
			TokenTypes     []string `json:"tokenTypes"`
			TokenModifiers []string `json:"tokenModifiers"`
		} `json:"legend"`
		Full  bool `json:"full"`
		Range bool `json:"range"`
	} `json:"semanticTokensProvider,omitempty"`
	FoldingRangeProvider bool `json:"foldingRangeProvider"`
}

type InitializeResult struct {
	Capabilities ServerCapabilities `json:"capabilities"`
	ServerInfo   map[string]string  `json:"serverInfo,omitempty"`
}

// ----- Diagnostics -----

type Diagnostic struct {
	Range    Range  `json:"range"`
	Severity int    `json:"severity,omitempty"` // 1 = Error
	Code     string `json:"code,omitempty"`
	Source   string `json:"source,omitempty"`
	Message  string `json:"message"`
}

type PublishDiagnosticsParams struct {
	URI         string       `json:"uri"`
	Diagnostics []Diagnostic `json:"diagnostics"`
}

// ----- Hover -----

type Hover struct {
	Contents MarkupContent `json:"contents"`
	Range    *Range        `json:"range,omitempty"`
}

type MarkupContent struct {
	Kind  string `json:"kind"`  // "plaintext" or "markdown"
	Value string `json:"value"` // content
}

// ----- Completion -----

type CompletionItem struct {
	Label            string `json:"label"`
	Kind             int    `json:"kind,omitempty"`
	Detail           string `json:"detail,omitempty"`
	InsertText       string `json:"insertText,omitempty"`
	InsertTextFormat int    `json:"insertTextFormat,omitempty"`
}

// ----- Document symbols -----

type DocumentSymbol struct {
	Name           string           `json:"name"`
	Detail         string           `json:"detail,omitempty"`
	Kind           int              `json:"kind"`
	Range          Range            `json:"range"`
	SelectionRange Range            `json:"selectionRange"`
	Children       []DocumentSymbol `json:"children,omitempty"`
}

// ----- Semantic tokens -----

type SemanticTokensParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
}

type SemanticTokensRangeParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Range        Range                  `json:"range"`
}

type SemanticTokens struct {
	Data []uint32 `json:"data"`
}

// ----- Folding ranges -----

type FoldingRange struct {
	StartLine      int     `json:"startLine"`
	StartCharacter *int    `json:"startCharacter,omitempty"`
	EndLine        int     `json:"endLine"`
	EndCharacter   *int    `json:"endCharacter,omitempty"`
	Kind           *string `json:"kind,omitempty"` // "region", "comment"
}

// ----- Signature help -----

type SignatureHelpParams struct {
	TextDocument TextDocumentIdentifier `json:"textDocument"`
	Position     Position               `json:"position"`
}

type SignatureHelp struct {
	Signatures      []SignatureInformation `json:"signatures"`
	ActiveSignature int                    `json:"activeSignature"`
	ActiveParameter int                    `json:"activeParameter"`
}

type SignatureInformation struct {
	Label         string                 `json:"label"`
	Documentation *MarkupContent         `json:"documentation,omitempty"`
	Parameters    []ParameterInformation `json:"parameters,omitempty"`
}

type ParameterInformation struct {
	Label         string         `json:"label"`
	Documentation *MarkupContent `json:"documentation,omitempty"`
}
=== END FILE: cmd/msg-lsp/protocol.go ===

